conditions:
  - name: splade-v3-pytorch
    display: "SPLADEv3: Lucene, PyTorch"
    display-html: "SPLADEv3: Lucene, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lassance et al. (2024) SPLADE-v3: New baselines for SPLADE.\">15</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-v3 --topics $topics --encoder naver/splade-v3 --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3999
            R@1K: 0.9868
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5231
            nDCG@10: 0.7264
            R@1K: 0.8791
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5402
            nDCG@10: 0.7522
            R@1K: 0.9039
  - name: splade-v3-rocchio-pytorch
    display: "SPLADEv3 w/ Rocchio: Lucene, PyTorch"
    display-html: "SPLADEv3 w/ Rocchio: Lucene, PyTorch"
    display-row: ""
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-v3-text --topics $topics --encoder naver/splade-v3 --output $output --hits 1000 --impact --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3613
            R@1K: 0.9839
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5374
            nDCG@10: 0.7406
            R@1K: 0.8738
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5456
            nDCG@10: 0.7487
            R@1K: 0.9258
  - name: bge-base-en-v1.5.lucene-hnsw-int8.onnx
    display: "BGE-base-en-v1.5: Lucene quantized HNSW, ONNX"
    display-html: "BGE-base-en-v1.5: Lucene quantized HNSW, ONNX"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Xiao et al. (2023) C-Pack: Packaged Resources To Advance General Chinese Embedding.\">14</a>]"
    command: python -m pyserini.search.lucene --threads ${dense_threads} --batch-size ${dense_batch_size} --dense --hnsw --index msmarco-v1-passage.bge-base-en-v1.5.hnsw-int8 --topics $topics --onnx-encoder BgeBaseEn15 --output $output --hits 1000 --ef-search 1000
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3575
            R@1K: 0.9772
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4454
            nDCG@10: 0.7017
            R@1K: 0.8436
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4596
            nDCG@10: 0.6767
            R@1K: 0.8468
  - name: bge-base-en-v1.5.lucene-hnsw.onnx
    display: "BGE-base-en-v1.5: Lucene HNSW, ONNX"
    display-html: "BGE-base-en-v1.5: Lucene HNSW, ONNX"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Xiao et al. (2023) C-Pack: Packaged Resources To Advance General Chinese Embedding.\">14</a>]"
    command: python -m pyserini.search.lucene --threads ${dense_threads} --batch-size ${dense_batch_size} --dense --hnsw --index msmarco-v1-passage.bge-base-en-v1.5.hnsw --topics $topics --onnx-encoder BgeBaseEn15 --output $output --hits 1000 --ef-search 1000
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3575
            R@1K: 0.9788
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4486
            nDCG@10: 0.7016
            R@1K: 0.8441
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4626
            nDCG@10: 0.6768
            R@1K: 0.8526
  - name: bge-base-en-v1.5.faiss-flat.pytorch
    display: "BGE-base-en-v1.5: Faiss flat, PyTorch"
    display-html: "BGE-base-en-v1.5: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Xiao et al. (2023) C-Pack: Packaged Resources To Advance General Chinese Embedding.\">14</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm --query-prefix "Represent this sentence for searching relevant passages:" --index msmarco-v1-passage.bge-base-en-v1.5 --topics $topics --output $output --hits 1000
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3583
            R@1K: 0.9811
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4485
            nDCG@10: 0.7016
            R@1K: 0.8427
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4628
            nDCG@10: 0.6768
            R@1K: 0.8547
  - name: cosdpr-distil.lucene-hnsw-int8.onnx
    display: "cosDPR-distil: Lucene quantized HNSW, ONNX"
    display-html: "cosDPR-distil: Lucene quantized HNSW, ONNX"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (CIKM&nbsp;2023) Anserini Gets Dense Retrieval: Integration of Lucene's HNSW Indexes.\">13</a>]"
    command: python -m pyserini.search.lucene --threads ${dense_threads} --batch-size ${dense_batch_size} --dense --hnsw --index msmarco-v1-passage.cosdpr-distil.hnsw-int8 --topics $topics --onnx-encoder CosDprDistil --output $output --hits 1000 --ef-search 1000
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3899
            R@1K: 0.9764
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4664
            nDCG@10: 0.7247
            R@1K: 0.8218
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4871
            nDCG@10: 0.6996
            R@1K: 0.8538
  - name: cosdpr-distil.lucene-hnsw.onnx
    display: "cosDPR-distil: Lucene HNSW, ONNX"
    display-html: "cosDPR-distil: Lucene HNSW, ONNX"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (CIKM&nbsp;2023) Anserini Gets Dense Retrieval: Integration of Lucene's HNSW Indexes.\">13</a>]"
    command: python -m pyserini.search.lucene --threads ${dense_threads} --batch-size ${dense_batch_size} --dense --hnsw --index msmarco-v1-passage.cosdpr-distil.hnsw --topics $topics --onnx-encoder CosDprDistil --output $output --hits 1000 --ef-search 1000
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3887
            R@1K: 0.9765
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4660
            nDCG@10: 0.7250
            R@1K: 0.8222
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4876
            nDCG@10: 0.7025
            R@1K: 0.8540
  - name: cosdpr-distil.faiss-flat.pytorch
    display: "cosDPR-distil: Faiss flat, PyTorch"
    display-html: "cosDPR-distil: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (CIKM&nbsp;2023) Anserini Gets Dense Retrieval: Integration of Lucene's HNSW Indexes.\">13</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.cosdpr-distil --topics $topics --encoder castorini/cosdpr-distil --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3896
            R@1K: 0.9796
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4656
            nDCG@10: 0.7250
            R@1K: 0.8201
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4876
            nDCG@10: 0.7025
            R@1K: 0.8533
  - name: splade-pp-ed-rocchio-pytorch
    display: "SPLADE++ EnsembleDistil w/ Rocchio: Lucene, PyTorch"
    display-html: "SPLADE++ EnsembleDistil w/ Rocchio: Lucene, PyTorch"
    display-row: ""
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-ed-text --topics $topics --encoder naver/splade-cocondenser-ensembledistil --output $output --hits 1000 --impact --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3301
            R@1K: 0.9811
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5140
            nDCG@10: 0.7119
            R@1K: 0.8799
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5084
            nDCG@10: 0.7280
            R@1K: 0.9069
  - name: splade-pp-sd-rocchio-pytorch
    display: "SPLADE++ SelfDistil w/ Rocchio: Lucene, PyTorch"
    display-html: "SPLADE++ SelfDistil w/ Rocchio: Lucene, PyTorch"
    display-row: ""
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-sd-text --topics $topics --encoder naver/splade-cocondenser-selfdistil --output $output --hits 1000 --impact --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3278
            R@1K: 0.9824
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5072
            nDCG@10: 0.7156
            R@1K: 0.8918
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5335
            nDCG@10: 0.7388
            R@1K: 0.9120
  - name: splade-pp-ed-pytorch
    display: "SPLADE++ EnsembleDistil: Lucene, PyTorch"
    display-html: "SPLADE++ EnsembleDistil: Lucene, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Formal et al. (SIGIR 2022) From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective.\">2</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-ed --topics $topics --encoder naver/splade-cocondenser-ensembledistil --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3828
            R@1K: 0.9831
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5050
            nDCG@10: 0.7308
            R@1K: 0.8728
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4999
            nDCG@10: 0.7197
            R@1K: 0.8998
  - name: splade-pp-sd-pytorch
    display: "SPLADE++ SelfDistil: Lucene, PyTorch"
    display-html: "SPLADE++ SelfDistil: Lucene, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Formal et al. (SIGIR 2022) From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective.\">2</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-sd --topics $topics --encoder naver/splade-cocondenser-selfdistil --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3776
            R@1K: 0.9846
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4998
            nDCG@10: 0.7358
            R@1K: 0.8761
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5139
            nDCG@10: 0.7282
            R@1K: 0.9024
  - name: splade-pp-ed-rocchio-onnx
    display: "SPLADE++ EnsembleDistil w/ Rocchio: Lucene, ONNX"
    display-html: "SPLADE++ EnsembleDistil w/ Rocchio: Lucene, ONNX"
    display-row: ""
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-ed-text --topics $topics --onnx-encoder SpladePlusPlusEnsembleDistil --output $output --hits 1000 --impact --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3300
            R@1K: 0.9811
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5140
            nDCG@10: 0.7119
            R@1K: 0.8799
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5084
            nDCG@10: 0.7280
            R@1K: 0.9069
  - name: splade-pp-sd-rocchio-onnx
    display: "SPLADE++ SelfDistil w/ Rocchio: Lucene, ONNX"
    display-html: "SPLADE++ SelfDistil w/ Rocchio: Lucene, ONNX"
    display-row: ""
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-sd-text --topics $topics --onnx-encoder SpladePlusPlusSelfDistil --output $output --hits 1000 --impact --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3278
            R@1K: 0.9824
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5072
            nDCG@10: 0.7156
            R@1K: 0.8918
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5335
            nDCG@10: 0.7388
            R@1K: 0.9120
  - name: bm25-rocchio-d2q-t5-tuned
    display: "BM25+Rocchio w/ doc2query-T5 (k1=2.18, b=0.86): Lucene"
    display-html: "BM25+Rocchio w/ doc2query-T5 (<i>k<sub><small>1</small></sub></i>=2.18, <i>b</i>=0.86): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.d2q-t5-docvectors --topics $topics --output $output --bm25 --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2395
            R@1K: 0.9535
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4339
            nDCG@10: 0.6559
            R@1K: 0.8465
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4376
            nDCG@10: 0.6224
            R@1K: 0.8641
  - name: bm25-rocchio-d2q-t5-default
    display: "BM25+Rocchio w/ doc2query-T5 (k1=0.9, b=0.4): Lucene"
    display-html: "BM25+Rocchio w/ doc2query-T5 (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.d2q-t5-docvectors --topics $topics --output $output --bm25 --rocchio --k1 0.9 --b 0.4
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2158
            R@1K: 0.9467
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4469
            nDCG@10: 0.6538
            R@1K: 0.8855
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4246
            nDCG@10: 0.6102
            R@1K: 0.8675
  - name: bm25-rocchio-default
    display: "BM25+Rocchio (k1=0.9, b=0.4): Lucene"
    display-html: "BM25+Rocchio (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage --topics $topics --output $output --bm25 --k1 0.9 --b 0.4 --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.1595
            R@1K: 0.8620
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.3474
            nDCG@10: 0.5275
            R@1K: 0.8007
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.3115
            nDCG@10: 0.4910
            R@1K: 0.8156
  - name: bm25-rocchio-tuned
    display: "BM25+Rocchio (k1=0.82, b=0.68): Lucene"
    display-html: "BM25+Rocchio (<i>k<sub><small>1</small></sub></i>=0.82, <i>b</i>=0.68): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage --topics $topics --output $output --bm25 --rocchio
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.1684
            R@1K: 0.8726
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.3396
            nDCG@10: 0.5275
            R@1K: 0.7948
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.3120
            nDCG@10: 0.4908
            R@1K: 0.8327
  - name: distilbert-kd-tasb-pytorch
    display: "DistilBERT KD TASB: Faiss flat, PyTorch"
    display-html: "DistilBERT KD TASB: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Hofstätter et al. (SIGIR&nbsp;2021) Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling.\">5</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.distilbert-dot-tas_b-b256 --topics $topics --encoder sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3444
            R@1K: 0.9771
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4590
            nDCG@10: 0.7210
            R@1K: 0.8406
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4698
            nDCG@10: 0.6854
            R@1K: 0.8727
  - name: distilbert-kd-tasb-avg-prf-pytorch
    display: "DistilBERT KD TASB w/ Average PRF: Faiss flat, PyTorch"
    display-html: "DistilBERT KD TASB w/ Average PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.distilbert-dot-tas_b-b256 --topics $topics --encoder sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco --output $output --prf-method avg --prf-depth 3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2910
            R@1K: 0.9613
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4856
            nDCG@10: 0.7190
            R@1K: 0.8517
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4887
            nDCG@10: 0.7086
            R@1K: 0.9030
  - name: distilbert-kd-tasb-rocchio-prf-pytorch
    display: "DistilBERT KD TASB w/ Rocchio PRF: Faiss flat, PyTorch"
    display-html: "DistilBERT KD TASB w/ Rocchio PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.distilbert-dot-tas_b-b256 --topics $topics --encoder sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco --output $output --prf-method rocchio --prf-depth 5 --rocchio-alpha 0.4 --rocchio-beta 0.6 --rocchio-topk 5
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2896
            R@1K: 0.9702
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4974
            nDCG@10: 0.7231
            R@1K: 0.8775
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4879
            nDCG@10: 0.7083
            R@1K: 0.8926
  - name: distilbert-kd-pytorch
    display: "DistilBERT KD: Faiss flat, PyTorch"
    display-html: "DistilBERT KD: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Hofstätter et al. (2020) Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation.\">4</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.distilbert-dot-margin-mse-t2 --topics $topics --encoder sebastian-hofstaetter/distilbert-dot-margin_mse-T2-msmarco --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3251
            R@1K: 0.9553
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4053
            nDCG@10: 0.6994
            R@1K: 0.7653
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4159
            nDCG@10: 0.6447
            R@1K: 0.7953
  - name: ance-pytorch
    display: "ANCE: Faiss flat, PyTorch"
    display-html: "ANCE: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Xiong et al. (ICLR 2021) Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval.\">3</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.ance --topics $topics --encoder castorini/ance-msmarco-passage --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3301
            R@1K: 0.9587
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.3710
            nDCG@10: 0.6452
            R@1K: 0.7554
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4076
            nDCG@10: 0.6458
            R@1K: 0.7764
  - name: ance-avg-prf-pytorch
    display: "ANCE w/ Average PRF: Faiss flat, PyTorch"
    display-html: "ANCE w/ Average PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.ance --topics $topics --encoder castorini/ance-msmarco-passage --output $output --prf-method avg --prf-depth 3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3075
            R@1K: 0.9490
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4247
            nDCG@10: 0.6532
            R@1K: 0.7739
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4325
            nDCG@10: 0.6573
            R@1K: 0.7909
  - name: ance-rocchio-prf-pytorch
    display: "ANCE w/ Rocchio PRF: Faiss flat, PyTorch"
    display-html: "ANCE w/ Rocchio PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.ance --topics $topics --encoder castorini/ance-msmarco-passage --output $output --prf-method rocchio --prf-depth 5 --rocchio-alpha 0.4 --rocchio-beta 0.6 --rocchio-topk 5
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3048
            R@1K: 0.9547
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4211
            nDCG@10: 0.6539
            R@1K: 0.7825
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4315
            nDCG@10: 0.6471
            R@1K: 0.7957
  - name: sbert-pytorch
    display: "SBERT: Faiss flat, PyTorch"
    display-html: "SBERT: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Reimers et al. (EMNLP&nbsp;2019) Sentence-BERT: Sentence Embeddings using Siamese BERT-Network.\">10</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.sbert --topics $topics --encoder sentence-transformers/msmarco-distilbert-base-v3 --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3314
            R@1K: 0.9558
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4060
            nDCG@10: 0.6930
            R@1K: 0.7872
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4124
            nDCG@10: 0.6344
            R@1K: 0.7937
  - name: sbert-avg-prf-pytorch
    display: "SBERT w/ Average PRF: Faiss flat, PyTorch"
    display-html: "SBERT w/ Average PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.sbert --topics $topics --encoder sentence-transformers/msmarco-distilbert-base-v3 --output $output --prf-method avg --prf-depth 3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3035
            R@1K: 0.9446
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4354
            nDCG@10: 0.7001
            R@1K: 0.7937
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4258
            nDCG@10: 0.6412
            R@1K: 0.8169
  - name: sbert-rocchio-prf-pytorch
    display: "SBERT w/ Rocchio PRF: Faiss flat, PyTorch"
    display-html: "SBERT w/ Rocchio PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.sbert --topics $topics --encoder sentence-transformers/msmarco-distilbert-base-v3 --output $output --prf-method rocchio --prf-depth 5 --rocchio-alpha 0.4 --rocchio-beta 0.6 --rocchio-topk 5
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2972
            R@1K: 0.9529
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4371
            nDCG@10: 0.6952
            R@1K: 0.7941
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4342
            nDCG@10: 0.6559
            R@1K: 0.8226
  - name: bm25-tuned
    display: "BM25 (k1=0.82, b=0.68): Lucene"
    display-html: "BM25 (<i>k<sub><small>1</small></sub></i>=0.82, <i>b</i>=0.68): Lucene"
    command: python -m pyserini.search.lucene --topics $topics --index msmarco-v1-passage --output $output --bm25
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.1875
            R@1K: 0.8573
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.2903
            nDCG@10: 0.4973
            R@1K: 0.7450
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.2876
            nDCG@10: 0.4876
            R@1K: 0.8031
  - name: bm25-rm3-tuned
    display: "BM25+RM3 (k1=0.82, b=0.68): Lucene"
    display-html: "BM25+RM3 (<i>k<sub><small>1</small></sub></i>=0.82, <i>b</i>=0.68): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage --topics $topics --output $output --bm25 --rm3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.1646
            R@1K: 0.8704
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.3339
            nDCG@10: 0.5147
            R@1K: 0.7950
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.3017
            nDCG@10: 0.4924
            R@1K: 0.8292
  - name: bm25-default
    display: "BM25 (k1=0.9, b=0.4): Lucene"
    display-html: "BM25 (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4): Lucene"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (SIGIR 2022) Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2.\">1</a>]&nbsp;(1a)"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage --topics $topics --output $output --bm25 --k1 0.9 --b 0.4
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.1840
            R@1K: 0.8526
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.3013
            nDCG@10: 0.5058
            R@1K: 0.7501
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.2856
            nDCG@10: 0.4796
            R@1K: 0.7863
  - name: bm25-rm3-default
    display: "BM25+RM3 (k1=0.9, b=0.4): Lucene"
    display-html: "BM25+RM3 (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4): Lucene"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (SIGIR 2022) Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2.\">1</a>]&nbsp;(1b)"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage --topics $topics --output $output --bm25 --k1 0.9 --b 0.4 --rm3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.1566
            R@1K: 0.8606
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.3416
            nDCG@10: 0.5216
            R@1K: 0.8136
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.3006
            nDCG@10: 0.4896
            R@1K: 0.8236
  - name: bm25-d2q-t5-tuned
    display: "BM25 w/ doc2query-T5 (k1=2.18, b=0.86): Lucene"
    display-html: "BM25 w/ doc2query-T5 (<i>k<sub><small>1</small></sub></i>=2.18, <i>b</i>=0.86): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.d2q-t5 --topics $topics --output $output --bm25
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2816
            R@1K: 0.9506
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4046
            nDCG@10: 0.6336
            R@1K: 0.8134
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4171
            nDCG@10: 0.6265
            R@1K: 0.8393
  - name: bm25-d2q-t5-default
    display: "BM25 w/ doc2query-T5 (k1=0.9, b=0.4): Lucene"
    display-html: "BM25 w/ doc2query-T5 (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4): Lucene"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (SIGIR 2022) Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2.\">1</a>]&nbsp;(2a)"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.d2q-t5 --topics $topics --output $output --bm25 --k1 0.9 --b 0.4
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2723
            R@1K: 0.9470
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4034
            nDCG@10: 0.6417
            R@1K: 0.8310
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4074
            nDCG@10: 0.6187
            R@1K: 0.8452
  - name: bm25-rm3-d2q-t5-tuned
    display: "BM25+RM3 w/ doc2query-T5 (k1=2.18, b=0.86): Lucene"
    display-html: "BM25+RM3 w/ doc2query-T5 (<i>k<sub><small>1</small></sub></i>=2.18, <i>b</i>=0.86): Lucene"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.d2q-t5-docvectors --topics $topics --output $output --bm25 --rm3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2382
            R@1K: 0.9528
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4377
            nDCG@10: 0.6537
            R@1K: 0.8443
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4348
            nDCG@10: 0.6235
            R@1K: 0.8605
  - name: bm25-rm3-d2q-t5-default
    display: "BM25+RM3 w/ doc2query-T5 (k1=0.9, b=0.4): Lucene"
    display-html: "BM25+RM3 w/ doc2query-T5 (<i>k<sub><small>1</small></sub></i>=0.9, <i>b</i>=0.4): Lucene"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (SIGIR 2022) Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2.\">1</a>]&nbsp;(2b)"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.d2q-t5-docvectors --topics $topics --output $output --bm25 --rm3 --k1 0.9 --b 0.4
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.2139
            R@1K: 0.9460
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4483
            nDCG@10: 0.6586
            R@1K: 0.8863
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4286
            nDCG@10: 0.6131
            R@1K: 0.8700
  - name: unicoil-pytorch
    display: "uniCOIL (w/ doc2query-T5): Lucene, PyTorch"
    display-html: "uniCOIL (w/ doc2query-T5): Lucene, PyTorch"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.unicoil --topics $topics --encoder castorini/unicoil-msmarco-passage --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3509
            R@1K: 0.9583
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4612
            nDCG@10: 0.7024
            R@1K: 0.8292
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4430
            nDCG@10: 0.6745
            R@1K: 0.8430
  - name: unicoil-onnx
    display: "uniCOIL (w/ doc2query-T5): Lucene, ONNX"
    display-html: "uniCOIL (w/ doc2query-T5): Lucene, ONNX"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.unicoil --topics $topics --onnx-encoder UniCoil --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3509
            R@1K: 0.9583
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4612
            nDCG@10: 0.7024
            R@1K: 0.8292
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4430
            nDCG@10: 0.6745
            R@1K: 0.8430
  - name: unicoil
    display: "uniCOIL (w/ doc2query-T5): Lucene, cached queries"
    display-html: "uniCOIL (w/ doc2query-T5): Lucene, cached queries"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (SIGIR 2022) Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2.\">1</a>]&nbsp;(3b)"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.unicoil --topics $topics --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev.unicoil
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3516
            R@1K: 0.9582
      - topic_key: dl19-passage.unicoil
        eval_key: dl19-passage
        scores:
          - MAP: 0.4612
            nDCG@10: 0.7024
            R@1K: 0.8292
      - topic_key: dl20-passage.unicoil
        eval_key: dl20-passage
        scores:
          - MAP: 0.4430
            nDCG@10: 0.6745
            R@1K: 0.8430
  - name: unicoil-noexp-pytorch
    display: "uniCOIL (noexp): Lucene, PyTorch"
    display-html: "uniCOIL (noexp): Lucene, PyTorch"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.unicoil-noexp --topics $topics --encoder castorini/unicoil-noexp-msmarco-passage --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3153
            R@1K: 0.9239
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4033
            nDCG@10: 0.6433
            R@1K: 0.7752
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4021
            nDCG@10: 0.6523
            R@1K: 0.7861
  - name: unicoil-noexp-onnx
    display: "uniCOIL (noexp): Lucene, ONNX"
    display-html: "uniCOIL (noexp): Lucene, ONNX"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.unicoil-noexp --topics $topics --onnx-encoder UniCoil --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3120
            R@1K: 0.9239
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4059
            nDCG@10: 0.6535
            R@1K: 0.7811
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.3908
            nDCG@10: 0.6400
            R@1K: 0.7910
  - name: unicoil-noexp
    display: "uniCOIL (noexp): Lucene, cached queries"
    display-html: "uniCOIL (noexp): Lucene, cached queries"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Ma et al. (SIGIR 2022) Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2.\">1</a>]&nbsp;(3a)"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.unicoil-noexp --topics $topics --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev.unicoil-noexp
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3153
            R@1K: 0.9239
      - topic_key: dl19-passage.unicoil-noexp
        eval_key: dl19-passage
        scores:
          - MAP: 0.4033
            nDCG@10: 0.6433
            R@1K: 0.7752
      - topic_key: dl20-passage.unicoil-noexp
        eval_key: dl20-passage
        scores:
          - MAP: 0.4021
            nDCG@10: 0.6523
            R@1K: 0.7861
  - name: splade-pp-ed-onnx
    display: "SPLADE++ EnsembleDistil: Lucene, ONNX"
    display-html: "SPLADE++ EnsembleDistil: Lucene, ONNX"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Formal et al. (SIGIR 2022) From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective.\">2</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-ed --topics $topics --onnx-encoder SpladePlusPlusEnsembleDistil --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3828
            R@1K: 0.9831
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5050
            nDCG@10: 0.7308
            R@1K: 0.8728
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4999
            nDCG@10: 0.7197
            R@1K: 0.8998
  - name: splade-pp-sd-onnx
    display: "SPLADE++ SelfDistil: Lucene, ONNX"
    display-html: "SPLADE++ SelfDistil: Lucene, ONNX"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Formal et al. (SIGIR 2022) From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective.\">2</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.splade-pp-sd --topics $topics --onnx-encoder SpladePlusPlusSelfDistil --output $output --hits 1000 --impact
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3776
            R@1K: 0.9846
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4998
            nDCG@10: 0.7358
            R@1K: 0.8761
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5139
            nDCG@10: 0.7282
            R@1K: 0.9024
  - name: tct_colbert-v2-hnp-pytorch
    display: "TCT_ColBERT-V2-HN+: Faiss flat, PyTorch"
    display-html: "TCT_ColBERT-V2-HN+: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lin et al. (2021) In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval.\">6</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.tct_colbert-v2-hnp --topics $topics --encoder castorini/tct_colbert-v2-hnp-msmarco --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3584
            R@1K: 0.9695
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4469
            nDCG@10: 0.7204
            R@1K: 0.8261
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4754
            nDCG@10: 0.6882
            R@1K: 0.8429
  - name: tct_colbert-v2-hnp-avg-prf-pytorch
    display: "TCT_ColBERT-V2-HN+ w/ Average PRF: Faiss flat, PyTorch"
    display-html: "TCT_ColBERT-V2-HN+ w/ Average PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.tct_colbert-v2-hnp --topics $topics --encoder castorini/tct_colbert-v2-hnp-msmarco --output $output --prf-method avg --prf-depth 3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3121
            R@1K: 0.9585
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4879
            nDCG@10: 0.7312
            R@1K: 0.8586
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4811
            nDCG@10: 0.6836
            R@1K: 0.8579
  - name: tct_colbert-v2-hnp-rocchio-prf-pytorch
    display: "TCT_ColBERT-V2-HN+ w/ Rocchio PRF: Faiss flat, PyTorch"
    display-html: "TCT_ColBERT-V2-HN+ w/ Rocchio PRF: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (TOIS 2023) Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls.\">9</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.tct_colbert-v2-hnp --topics $topics --encoder castorini/tct_colbert-v2-hnp-msmarco --output $output --prf-method rocchio --prf-depth 5 --rocchio-alpha 0.4 --rocchio-beta 0.6 --rocchio-topk 5
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3125
            R@1K: 0.9659
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4883
            nDCG@10: 0.7111
            R@1K: 0.8694
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4860
            nDCG@10: 0.6804
            R@1K: 0.8518
  - name: tct_colbert-v2-hnp-bm25-pytorch
    display: "Hybrid TCT_ColBERT-V2-HN+ and BM25: PyTorch"
    display-html: "Hybrid TCT_ColBERT-V2-HN+ and BM25: PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lin et al. (2021) In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval.\">6</a>]"
    command: python -m pyserini.search.hybrid dense --index msmarco-v1-passage.tct_colbert-v2-hnp --encoder castorini/tct_colbert-v2-hnp-msmarco sparse --index msmarco-v1-passage fusion --alpha 0.06 run --threads ${dense_threads} --batch-size ${dense_batch_size} --topics $topics --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3683
            R@1K: 0.9707
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4697
            nDCG@10: 0.7320
            R@1K: 0.8802
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4859
            nDCG@10: 0.7016
            R@1K: 0.8898
  - name: tct_colbert-v2-hnp-bm25d2q-pytorch
    display: "Hybrid TCT_ColBERT-V2-HN+ and BM25 doc2query: PyTorch"
    display-html: "Hybrid TCT_ColBERT-V2-HN+ and BM25 doc2query: PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lin et al. (2021) In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval.\">6</a>]"
    command: python -m pyserini.search.hybrid dense --index msmarco-v1-passage.tct_colbert-v2-hnp --encoder castorini/tct_colbert-v2-hnp-msmarco sparse --index msmarco-v1-passage.d2q-t5 fusion --alpha 0.1 run --threads ${dense_threads} --batch-size ${dense_batch_size} --topics $topics --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3731
            R@1K: 0.9759
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4829
            nDCG@10: 0.7376
            R@1K: 0.8614
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5078
            nDCG@10: 0.7244
            R@1K: 0.8847
  - name: slimr
    display: "SLIM: Lucene, PyTorch"
    display-html: "SLIM: Lucene, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (SIGIR 2023) SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes.\">7</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.slimr --topics $topics --encoder castorini/slimr-msmarco-passage --encoded-corpus scipy-sparse-vectors.msmarco-v1-passage-slimr --output $output --output-format msmarco --hits 1000 --impact --min-idf 3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3581
            R@1K: 0.9622
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4509
            nDCG@10: 0.7010
            R@1K: 0.8241
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4419
            nDCG@10: 0.6403
            R@1K: 0.8543
  - name: slimr-pp
    display: "SLIM++: Lucene, PyTorch"
    display-html: "SLIM++: Lucene, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Li et al. (SIGIR 2023) SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes.\">7</a>]"
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index msmarco-v1-passage.slimr-pp --topics $topics --encoder castorini/slimr-pp-msmarco-passage --encoded-corpus scipy-sparse-vectors.msmarco-v1-passage-slimr-pp --output $output --output-format msmarco --hits 1000 --impact --min-idf 3
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.4032
            R@1K: 0.9680
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4687
            nDCG@10: 0.7140
            R@1K: 0.8415
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4906
            nDCG@10: 0.7021
            R@1K: 0.8551
  - name: aggretriever-distilbert-pytorch
    display: "Aggretriever-DistilBERT: Faiss flat, PyTorch"
    display-html: "Aggretriever-DistilBERT: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lin et al. (TACL&nbsp;2023) Aggretriever: A Simple Approach to Aggregate Textual Representation for Robust Dense Passage Retrieval.\">8</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.aggretriever-distilbert --topics $topics --encoder castorini/aggretriever-distilbert --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3412
            R@1K: 0.9604
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4301
            nDCG@10: 0.6816
            R@1K: 0.8023
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4329
            nDCG@10: 0.6726
            R@1K: 0.8351
  - name: aggretriever-cocondenser-pytorch
    display: "Aggretriever-coCondenser: Faiss flat, PyTorch"
    display-html: "Aggretriever-coCondenser: Faiss flat, PyTorch"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lin et al. (TACL&nbsp;2023) Aggretriever: A Simple Approach to Aggregate Textual Representation for Robust Dense Passage Retrieval.\">8</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.aggretriever-cocondenser --topics $topics --encoder castorini/aggretriever-cocondenser --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3619
            R@1K: 0.9735
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4350
            nDCG@10: 0.6837
            R@1K: 0.8078
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4710
            nDCG@10: 0.6972
            R@1K: 0.8555
  - name: openai-ada2
    display: "OpenAI ada2: Faiss flat, cached queries"
    display-html: "OpenAI ada2: Faiss flat, cached queries"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Lin et al. (2023) Vector Search with OpenAI Embeddings: Lucene Is All You Need.\">11</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.openai-ada2 --topics $topics --encoded-queries $topics.openai-ada2 --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3435
            R@1K: 0.9858
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4788
            nDCG@10: 0.7035
            R@1K: 0.8629
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4771
            nDCG@10: 0.6759
            R@1K: 0.8705
  - name: openai-ada2-hyde
    display: "HyDE-OpenAI ada2: Faiss flat, cached queries"
    display-html: "HyDE-OpenAI ada2: Faiss flat, cached queries"
    display-row: "[<a href=\"#\" data-mdb-toggle=\"tooltip\" title=\"Gao et al. (ACL&nbsp;2023) Precise Zero-Shot Dense Retrieval without Relevance Labels.\">12</a>]"
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.openai-ada2 --topics $topics --encoded-queries $topics.openai-ada2-hyde --output $output
    topics:
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5125
            nDCG@10: 0.7163
            R@1K: 0.9002
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.4938
            nDCG@10: 0.6666
            R@1K: 0.8919
  - name: openai-text-embedding-3-large
    display: "OpenAI text-embedding-3-large: Faiss flat, cached queries"
    display-html: "OpenAI text-embedding-3-large: Faiss flat, cached queries"
    display-row: ""
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.openai-text-embedding-3-large --topics $topics --encoded-queries $topics.openai-text-embedding-3-large --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3342
            R@1K: 0.9885
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.5259
            nDCG@10: 0.7173
            R@1K: 0.8991
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5134
            nDCG@10: 0.7163
            R@1K: 0.8884
  - name: cohere-embed-english-v3.0
    display: "Cohere Embed English v3.0: Faiss flat, cached queries"
    display-html: "Cohere Embed English v3.0: Faiss flat, cached queries"
    display-row: ""
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index msmarco-v1-passage.cohere-embed-english-v3.0 --topics $topics --encoded-queries $topics.cohere-embed-english-v3.0 --output $output
    topics:
      - topic_key: msmarco-v1-passage.dev
        eval_key: msmarco-v1-passage.dev
        scores:
          - MRR@10: 0.3660
            R@1K: 0.9785
      - topic_key: dl19-passage
        eval_key: dl19-passage
        scores:
          - MAP: 0.4884
            nDCG@10: 0.6956
            R@1K: 0.8630
      - topic_key: dl20-passage
        eval_key: dl20-passage
        scores:
          - MAP: 0.5067
            nDCG@10: 0.7245
            R@1K: 0.8682
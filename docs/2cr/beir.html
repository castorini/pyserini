<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <title>Pyserini Reproductions</title>
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css" />
    <!-- Google Fonts Roboto -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" />
    <!-- MDB -->
   <link href="https://cdnjs.cloudflare.com/ajax/libs/mdb-ui-kit/4.0.0/mdb.min.css" rel="stylesheet" />

    <style>
tr.hide-table-padding td {
  padding: 0;
}

.expand-button {
  position: relative;
}

.accordion-toggle .expand-button:after {
  position: absolute;
  left:.75rem;
  top: 50%;
  transform: translate(0, -50%);
  content: '-';
}

.accordion-toggle.collapsed .expand-button:after {
  content: '+';
}

blockquote.mycode {
  border-left: 3px solid #ccc;
  margin-left: 25px;
  margin-top: 15px;
  padding-left: 15px;
}

blockquote.mycode2 {
  border-left: 3px solid #ccc;
  margin-left: 25px;
  padding-top: 10px;
  padding-bottom: 10px;
  padding-left: 15px;
}

tr th.headertop {
  border-bottom: none;
  padding-bottom: 0rem
}

tr th.headerbottom {
  padding-top: 0rem
}

.table>:not(caption)>*>*{padding:0.75rem 0.75rem}

.copy-code-button {
	border-radius: 0;
	min-width: 55px;
	background: none repeat scroll 0 0 transparent;
	background-color: grey;
	color: #F1F2F3 !important;
	cursor: pointer;
	border-style: none;
	font-family: 'HELVETICA',sans-serif;
	font-size: 0.8em;
	font-weight: normal;
	text-align: center;
	text-decoration: none;
	text-indent: 0;
	text-transform: uppercase;
	font-weight: 500;
	line-height: 1.42rem;
	margin: 0;
	padding: 3px 8px;
	position: absolute !important;
	top: 0 !important;
	right: 0 !important;
}

.copy-code-button > span {
	color: #F1F2F3 !important;
}

.copy-code-button, ::before, ::after {
	box-sizing: inherit;
}

.copy-code-button::before {
	content: '';
	display: inline-block;
	width: 16px;
	height: 16px;
	margin-right: 3px;
	background-size: contain;
	background-image: url("data:image/svg+xml;base64,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");
	background-repeat: no-repeat;
	position: relative;
	top: 3px;
}

.copy-code-button:focus {
    /* Avoid an ugly focus outline on click in Chrome,
       but darken the button for accessibility.
       See https://stackoverflow.com/a/25298082/1481479 */
    /* background-color: #E6E6E6; */
	outline: 0;
}

pre[class*="prettyprint"] {
	position: relative;
	overflow: hidden;
}
    </style>
</head>
<body>

    <!-- Background image -->
    <div id="intro" class="bg-image vh-100 shadow-1-strong" style="max-height: 150px">
      <div class="mask" style="
            background: linear-gradient(
              45deg,
              rgba(29, 236, 197, 0.7),
              rgba(91, 14, 214, 0.7) 100%
            );
          ">
        <div class="container d-flex align-items-center justify-content-center text-center h-100"  style="max-height: 150px">
          <div class="text-white">
            <h1 class="mb-3">BEIR</h1>
          </div>
        </div>
      </div>
    </div>
    <!-- Background image -->

<div class="container my-4">

<p>The two-click<a href="#" data-mdb-toggle="tooltip" title="What are the two clicks, you ask? Copy and paste!"><sup>*</sup></a> reproduction matrix below provides commands for reproducing the experimental results below.
Instructions for programmatic execution are shown at the bottom of this page (scroll down).</p>

<p>Key:</p>

<ul>
  <li>BM25 Flat: BM25 "flat" baseline [1]</li>
  <li>BM25 Multifield: BM25 "multifield" baseline [1]</li>
  <li>SPLADE: SPLADE++ (CoCondenser-EnsembleDistil) [2]</li>
  <li>Contriever-msmarco: Contriever FT MS MARCO [3]</li>
  <li>BGE-base: BGE-base-en-v1.5 [4]</li>
  <li>Cohere embed-english: Cohere embed-english-v3.0 [5]</li>
</ul>

<div class="table-responsive">
  <table class="table">
    <thead>
      <tr>
        <th class="headertop"></th>
        <th class="headertop"></th>
        <th class="headertop" colspan="3"><b>BM25 Flat</b></th>
        <th class="headertop" colspan="3"><b>BM25 Multifield</b></th>
        <th class="headertop" colspan="3"><b>SPLADE++ ED</b></th>
        <th class="headertop" colspan="3"><b>Contriever MSMARCO</b></th>
        <th class="headertop" colspan="3"><b>BGE-base</b></th>
        <th class="headertop" colspan="3"><b>Cohere embed-english</b></th>
      </tr>
      <tr>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
      </tr>
    </thead>
    <tbody>

<!-- Condition: trec-covid -->
<tr class="accordion-toggle collapsed" id="row1" data-toggle="collapse" data-parent="#row1" href="#collapse1">
<td class="expand-button"></td>
<td>trec-covid</td>
<td>  0.5947</td>
<td>  0.1091</td>
<td></td>
<td>  0.6559</td>
<td>  0.1141</td>
<td></td>
<td>  0.7274</td>
<td>  0.1282</td>
<td></td>
<td>  0.5964</td>
<td>  0.0907</td>
<td></td>
<td>  0.7815</td>
<td>  0.1406</td>
<td></td>
<td>  0.8178</td>
<td>  0.1594</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse1" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row1-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row1-tab1-header" data-mdb-toggle="tab" href="#row1-tab1" role="tab" aria-controls="row1-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row1-tab2-header" data-mdb-toggle="tab" href="#row1-tab2" role="tab" aria-controls="row1-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row1-tab3-header" data-mdb-toggle="tab" href="#row1-tab3" role="tab" aria-controls="row1-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row1-tab4-header" data-mdb-toggle="tab" href="#row1-tab4" role="tab" aria-controls="row1-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row1-tab5-header" data-mdb-toggle="tab" href="#row1-tab5" role="tab" aria-controls="row1-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row1-tab6-header" data-mdb-toggle="tab" href="#row1-tab6" role="tab" aria-controls="row1-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row1-content">
  <div class="tab-pane fade show active" id="row1-tab1" role="tabpanel" aria-labelledby="row1-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-trec-covid.flat \
  --topics beir-v1.0.0-trec-covid-test \
  --output run.beir.bm25-flat.trec-covid.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-covid-test \
  run.beir.bm25-flat.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-covid-test \
  run.beir.bm25-flat.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-covid-test \
  run.beir.bm25-flat.trec-covid.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row1-tab2" role="tabpanel" aria-labelledby="row1-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-trec-covid.multifield \
  --topics beir-v1.0.0-trec-covid-test \
  --output run.beir.bm25-multifield.trec-covid.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-covid-test \
  run.beir.bm25-multifield.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-covid-test \
  run.beir.bm25-multifield.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-covid-test \
  run.beir.bm25-multifield.trec-covid.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row1-tab3" role="tabpanel" aria-labelledby="row1-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-trec-covid.splade-pp-ed \
  --topics beir-v1.0.0-trec-covid.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.trec-covid.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-covid-test \
  run.beir.splade-pp-ed.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-covid-test \
  run.beir.splade-pp-ed.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-covid-test \
  run.beir.splade-pp-ed.trec-covid.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row1-tab4" role="tabpanel" aria-labelledby="row1-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-trec-covid.contriever-msmarco \
  --topics beir-v1.0.0-trec-covid-test \
  --output run.beir.contriever-msmarco.trec-covid.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-covid-test \
  run.beir.contriever-msmarco.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-covid-test \
  run.beir.contriever-msmarco.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-covid-test \
  run.beir.contriever-msmarco.trec-covid.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row1-tab5" role="tabpanel" aria-labelledby="row1-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-trec-covid.bge-base-en-v1.5 \
  --topics beir-v1.0.0-trec-covid-test \
  --output run.beir.bge-base-en-v1.5.trec-covid.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-covid-test \
  run.beir.bge-base-en-v1.5.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-covid-test \
  run.beir.bge-base-en-v1.5.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-covid-test \
  run.beir.bge-base-en-v1.5.trec-covid.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row1-tab6" role="tabpanel" aria-labelledby="row1-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-trec-covid.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-trec-covid-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-trec-covid-test \
  --output run.beir.cohere-embed-english-v3.0.trec-covid.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-covid-test \
  run.beir.cohere-embed-english-v3.0.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-covid-test \
  run.beir.cohere-embed-english-v3.0.trec-covid.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-covid-test \
  run.beir.cohere-embed-english-v3.0.trec-covid.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: bioasq -->
<tr class="accordion-toggle collapsed" id="row2" data-toggle="collapse" data-parent="#row2" href="#collapse2">
<td class="expand-button"></td>
<td>bioasq</td>
<td>  0.5225</td>
<td>  0.7687</td>
<td></td>
<td>  0.4646</td>
<td>  0.7145</td>
<td></td>
<td>  0.4980</td>
<td>  0.7385</td>
<td></td>
<td>  0.3829</td>
<td>  0.6072</td>
<td></td>
<td>  0.4148</td>
<td>  0.6316</td>
<td></td>
<td>  0.4565</td>
<td>  0.6790</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse2" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row2-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row2-tab1-header" data-mdb-toggle="tab" href="#row2-tab1" role="tab" aria-controls="row2-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row2-tab2-header" data-mdb-toggle="tab" href="#row2-tab2" role="tab" aria-controls="row2-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row2-tab3-header" data-mdb-toggle="tab" href="#row2-tab3" role="tab" aria-controls="row2-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row2-tab4-header" data-mdb-toggle="tab" href="#row2-tab4" role="tab" aria-controls="row2-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row2-tab5-header" data-mdb-toggle="tab" href="#row2-tab5" role="tab" aria-controls="row2-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row2-tab6-header" data-mdb-toggle="tab" href="#row2-tab6" role="tab" aria-controls="row2-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row2-content">
  <div class="tab-pane fade show active" id="row2-tab1" role="tabpanel" aria-labelledby="row2-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-bioasq.flat \
  --topics beir-v1.0.0-bioasq-test \
  --output run.beir.bm25-flat.bioasq.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-bioasq-test \
  run.beir.bm25-flat.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-bioasq-test \
  run.beir.bm25-flat.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-bioasq-test \
  run.beir.bm25-flat.bioasq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row2-tab2" role="tabpanel" aria-labelledby="row2-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-bioasq.multifield \
  --topics beir-v1.0.0-bioasq-test \
  --output run.beir.bm25-multifield.bioasq.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-bioasq-test \
  run.beir.bm25-multifield.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-bioasq-test \
  run.beir.bm25-multifield.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-bioasq-test \
  run.beir.bm25-multifield.bioasq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row2-tab3" role="tabpanel" aria-labelledby="row2-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-bioasq.splade-pp-ed \
  --topics beir-v1.0.0-bioasq.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.bioasq.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-bioasq-test \
  run.beir.splade-pp-ed.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-bioasq-test \
  run.beir.splade-pp-ed.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-bioasq-test \
  run.beir.splade-pp-ed.bioasq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row2-tab4" role="tabpanel" aria-labelledby="row2-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-bioasq.contriever-msmarco \
  --topics beir-v1.0.0-bioasq-test \
  --output run.beir.contriever-msmarco.bioasq.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-bioasq-test \
  run.beir.contriever-msmarco.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-bioasq-test \
  run.beir.contriever-msmarco.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-bioasq-test \
  run.beir.contriever-msmarco.bioasq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row2-tab5" role="tabpanel" aria-labelledby="row2-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-bioasq.bge-base-en-v1.5 \
  --topics beir-v1.0.0-bioasq-test \
  --output run.beir.bge-base-en-v1.5.bioasq.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-bioasq-test \
  run.beir.bge-base-en-v1.5.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-bioasq-test \
  run.beir.bge-base-en-v1.5.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-bioasq-test \
  run.beir.bge-base-en-v1.5.bioasq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row2-tab6" role="tabpanel" aria-labelledby="row2-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-bioasq.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-bioasq-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-bioasq-test \
  --output run.beir.cohere-embed-english-v3.0.bioasq.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-bioasq-test \
  run.beir.cohere-embed-english-v3.0.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-bioasq-test \
  run.beir.cohere-embed-english-v3.0.bioasq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-bioasq-test \
  run.beir.cohere-embed-english-v3.0.bioasq.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: nfcorpus -->
<tr class="accordion-toggle collapsed" id="row3" data-toggle="collapse" data-parent="#row3" href="#collapse3">
<td class="expand-button"></td>
<td>nfcorpus</td>
<td>  0.3218</td>
<td>  0.2457</td>
<td></td>
<td>  0.3254</td>
<td>  0.2500</td>
<td></td>
<td>  0.3470</td>
<td>  0.2844</td>
<td></td>
<td>  0.3281</td>
<td>  0.3008</td>
<td></td>
<td>  0.3735</td>
<td>  0.3368</td>
<td></td>
<td>  0.3863</td>
<td>  0.3512</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse3" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row3-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row3-tab1-header" data-mdb-toggle="tab" href="#row3-tab1" role="tab" aria-controls="row3-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row3-tab2-header" data-mdb-toggle="tab" href="#row3-tab2" role="tab" aria-controls="row3-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row3-tab3-header" data-mdb-toggle="tab" href="#row3-tab3" role="tab" aria-controls="row3-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row3-tab4-header" data-mdb-toggle="tab" href="#row3-tab4" role="tab" aria-controls="row3-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row3-tab5-header" data-mdb-toggle="tab" href="#row3-tab5" role="tab" aria-controls="row3-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row3-tab6-header" data-mdb-toggle="tab" href="#row3-tab6" role="tab" aria-controls="row3-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row3-content">
  <div class="tab-pane fade show active" id="row3-tab1" role="tabpanel" aria-labelledby="row3-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-nfcorpus.flat \
  --topics beir-v1.0.0-nfcorpus-test \
  --output run.beir.bm25-flat.nfcorpus.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nfcorpus-test \
  run.beir.bm25-flat.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nfcorpus-test \
  run.beir.bm25-flat.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nfcorpus-test \
  run.beir.bm25-flat.nfcorpus.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row3-tab2" role="tabpanel" aria-labelledby="row3-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-nfcorpus.multifield \
  --topics beir-v1.0.0-nfcorpus-test \
  --output run.beir.bm25-multifield.nfcorpus.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nfcorpus-test \
  run.beir.bm25-multifield.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nfcorpus-test \
  run.beir.bm25-multifield.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nfcorpus-test \
  run.beir.bm25-multifield.nfcorpus.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row3-tab3" role="tabpanel" aria-labelledby="row3-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-nfcorpus.splade-pp-ed \
  --topics beir-v1.0.0-nfcorpus.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.nfcorpus.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nfcorpus-test \
  run.beir.splade-pp-ed.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nfcorpus-test \
  run.beir.splade-pp-ed.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nfcorpus-test \
  run.beir.splade-pp-ed.nfcorpus.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row3-tab4" role="tabpanel" aria-labelledby="row3-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-nfcorpus.contriever-msmarco \
  --topics beir-v1.0.0-nfcorpus-test \
  --output run.beir.contriever-msmarco.nfcorpus.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nfcorpus-test \
  run.beir.contriever-msmarco.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nfcorpus-test \
  run.beir.contriever-msmarco.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nfcorpus-test \
  run.beir.contriever-msmarco.nfcorpus.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row3-tab5" role="tabpanel" aria-labelledby="row3-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-nfcorpus.bge-base-en-v1.5 \
  --topics beir-v1.0.0-nfcorpus-test \
  --output run.beir.bge-base-en-v1.5.nfcorpus.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nfcorpus-test \
  run.beir.bge-base-en-v1.5.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nfcorpus-test \
  run.beir.bge-base-en-v1.5.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nfcorpus-test \
  run.beir.bge-base-en-v1.5.nfcorpus.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row3-tab6" role="tabpanel" aria-labelledby="row3-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-nfcorpus.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-nfcorpus-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-nfcorpus-test \
  --output run.beir.cohere-embed-english-v3.0.nfcorpus.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nfcorpus-test \
  run.beir.cohere-embed-english-v3.0.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nfcorpus-test \
  run.beir.cohere-embed-english-v3.0.nfcorpus.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nfcorpus-test \
  run.beir.cohere-embed-english-v3.0.nfcorpus.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: nq -->
<tr class="accordion-toggle collapsed" id="row4" data-toggle="collapse" data-parent="#row4" href="#collapse4">
<td class="expand-button"></td>
<td>nq</td>
<td>  0.3055</td>
<td>  0.7513</td>
<td></td>
<td>  0.3285</td>
<td>  0.7597</td>
<td></td>
<td>  0.5378</td>
<td>  0.9296</td>
<td></td>
<td>  0.4977</td>
<td>  0.9252</td>
<td></td>
<td>  0.5414</td>
<td>  0.9415</td>
<td></td>
<td>  0.6162</td>
<td>  0.9560</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse4" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row4-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row4-tab1-header" data-mdb-toggle="tab" href="#row4-tab1" role="tab" aria-controls="row4-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row4-tab2-header" data-mdb-toggle="tab" href="#row4-tab2" role="tab" aria-controls="row4-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row4-tab3-header" data-mdb-toggle="tab" href="#row4-tab3" role="tab" aria-controls="row4-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row4-tab4-header" data-mdb-toggle="tab" href="#row4-tab4" role="tab" aria-controls="row4-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row4-tab5-header" data-mdb-toggle="tab" href="#row4-tab5" role="tab" aria-controls="row4-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row4-tab6-header" data-mdb-toggle="tab" href="#row4-tab6" role="tab" aria-controls="row4-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row4-content">
  <div class="tab-pane fade show active" id="row4-tab1" role="tabpanel" aria-labelledby="row4-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-nq.flat \
  --topics beir-v1.0.0-nq-test \
  --output run.beir.bm25-flat.nq.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nq-test \
  run.beir.bm25-flat.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nq-test \
  run.beir.bm25-flat.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nq-test \
  run.beir.bm25-flat.nq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row4-tab2" role="tabpanel" aria-labelledby="row4-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-nq.multifield \
  --topics beir-v1.0.0-nq-test \
  --output run.beir.bm25-multifield.nq.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nq-test \
  run.beir.bm25-multifield.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nq-test \
  run.beir.bm25-multifield.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nq-test \
  run.beir.bm25-multifield.nq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row4-tab3" role="tabpanel" aria-labelledby="row4-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-nq.splade-pp-ed \
  --topics beir-v1.0.0-nq.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.nq.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nq-test \
  run.beir.splade-pp-ed.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nq-test \
  run.beir.splade-pp-ed.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nq-test \
  run.beir.splade-pp-ed.nq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row4-tab4" role="tabpanel" aria-labelledby="row4-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-nq.contriever-msmarco \
  --topics beir-v1.0.0-nq-test \
  --output run.beir.contriever-msmarco.nq.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nq-test \
  run.beir.contriever-msmarco.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nq-test \
  run.beir.contriever-msmarco.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nq-test \
  run.beir.contriever-msmarco.nq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row4-tab5" role="tabpanel" aria-labelledby="row4-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-nq.bge-base-en-v1.5 \
  --topics beir-v1.0.0-nq-test \
  --output run.beir.bge-base-en-v1.5.nq.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nq-test \
  run.beir.bge-base-en-v1.5.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nq-test \
  run.beir.bge-base-en-v1.5.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nq-test \
  run.beir.bge-base-en-v1.5.nq.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row4-tab6" role="tabpanel" aria-labelledby="row4-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-nq.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-nq-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-nq-test \
  --output run.beir.cohere-embed-english-v3.0.nq.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-nq-test \
  run.beir.cohere-embed-english-v3.0.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-nq-test \
  run.beir.cohere-embed-english-v3.0.nq.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-nq-test \
  run.beir.cohere-embed-english-v3.0.nq.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: hotpotqa -->
<tr class="accordion-toggle collapsed" id="row5" data-toggle="collapse" data-parent="#row5" href="#collapse5">
<td class="expand-button"></td>
<td>hotpotqa</td>
<td>  0.6330</td>
<td>  0.7957</td>
<td></td>
<td>  0.6027</td>
<td>  0.7400</td>
<td></td>
<td>  0.6868</td>
<td>  0.8177</td>
<td></td>
<td>  0.6376</td>
<td>  0.7772</td>
<td></td>
<td>  0.7259</td>
<td>  0.8726</td>
<td></td>
<td>  0.7072</td>
<td>  0.8232</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse5" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row5-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row5-tab1-header" data-mdb-toggle="tab" href="#row5-tab1" role="tab" aria-controls="row5-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row5-tab2-header" data-mdb-toggle="tab" href="#row5-tab2" role="tab" aria-controls="row5-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row5-tab3-header" data-mdb-toggle="tab" href="#row5-tab3" role="tab" aria-controls="row5-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row5-tab4-header" data-mdb-toggle="tab" href="#row5-tab4" role="tab" aria-controls="row5-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row5-tab5-header" data-mdb-toggle="tab" href="#row5-tab5" role="tab" aria-controls="row5-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row5-tab6-header" data-mdb-toggle="tab" href="#row5-tab6" role="tab" aria-controls="row5-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row5-content">
  <div class="tab-pane fade show active" id="row5-tab1" role="tabpanel" aria-labelledby="row5-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-hotpotqa.flat \
  --topics beir-v1.0.0-hotpotqa-test \
  --output run.beir.bm25-flat.hotpotqa.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-hotpotqa-test \
  run.beir.bm25-flat.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-hotpotqa-test \
  run.beir.bm25-flat.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-hotpotqa-test \
  run.beir.bm25-flat.hotpotqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row5-tab2" role="tabpanel" aria-labelledby="row5-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-hotpotqa.multifield \
  --topics beir-v1.0.0-hotpotqa-test \
  --output run.beir.bm25-multifield.hotpotqa.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-hotpotqa-test \
  run.beir.bm25-multifield.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-hotpotqa-test \
  run.beir.bm25-multifield.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-hotpotqa-test \
  run.beir.bm25-multifield.hotpotqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row5-tab3" role="tabpanel" aria-labelledby="row5-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-hotpotqa.splade-pp-ed \
  --topics beir-v1.0.0-hotpotqa.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.hotpotqa.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-hotpotqa-test \
  run.beir.splade-pp-ed.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-hotpotqa-test \
  run.beir.splade-pp-ed.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-hotpotqa-test \
  run.beir.splade-pp-ed.hotpotqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row5-tab4" role="tabpanel" aria-labelledby="row5-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-hotpotqa.contriever-msmarco \
  --topics beir-v1.0.0-hotpotqa-test \
  --output run.beir.contriever-msmarco.hotpotqa.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-hotpotqa-test \
  run.beir.contriever-msmarco.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-hotpotqa-test \
  run.beir.contriever-msmarco.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-hotpotqa-test \
  run.beir.contriever-msmarco.hotpotqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row5-tab5" role="tabpanel" aria-labelledby="row5-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-hotpotqa.bge-base-en-v1.5 \
  --topics beir-v1.0.0-hotpotqa-test \
  --output run.beir.bge-base-en-v1.5.hotpotqa.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-hotpotqa-test \
  run.beir.bge-base-en-v1.5.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-hotpotqa-test \
  run.beir.bge-base-en-v1.5.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-hotpotqa-test \
  run.beir.bge-base-en-v1.5.hotpotqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row5-tab6" role="tabpanel" aria-labelledby="row5-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-hotpotqa.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-hotpotqa-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-hotpotqa-test \
  --output run.beir.cohere-embed-english-v3.0.hotpotqa.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-hotpotqa-test \
  run.beir.cohere-embed-english-v3.0.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-hotpotqa-test \
  run.beir.cohere-embed-english-v3.0.hotpotqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-hotpotqa-test \
  run.beir.cohere-embed-english-v3.0.hotpotqa.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: fiqa -->
<tr class="accordion-toggle collapsed" id="row6" data-toggle="collapse" data-parent="#row6" href="#collapse6">
<td class="expand-button"></td>
<td>fiqa</td>
<td>  0.2361</td>
<td>  0.5395</td>
<td></td>
<td>  0.2361</td>
<td>  0.5395</td>
<td></td>
<td>  0.3475</td>
<td>  0.6314</td>
<td></td>
<td>  0.3293</td>
<td>  0.6558</td>
<td></td>
<td>  0.4065</td>
<td>  0.7415</td>
<td></td>
<td>  0.4214</td>
<td>  0.7357</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse6" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row6-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row6-tab1-header" data-mdb-toggle="tab" href="#row6-tab1" role="tab" aria-controls="row6-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row6-tab2-header" data-mdb-toggle="tab" href="#row6-tab2" role="tab" aria-controls="row6-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row6-tab3-header" data-mdb-toggle="tab" href="#row6-tab3" role="tab" aria-controls="row6-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row6-tab4-header" data-mdb-toggle="tab" href="#row6-tab4" role="tab" aria-controls="row6-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row6-tab5-header" data-mdb-toggle="tab" href="#row6-tab5" role="tab" aria-controls="row6-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row6-tab6-header" data-mdb-toggle="tab" href="#row6-tab6" role="tab" aria-controls="row6-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row6-content">
  <div class="tab-pane fade show active" id="row6-tab1" role="tabpanel" aria-labelledby="row6-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-fiqa.flat \
  --topics beir-v1.0.0-fiqa-test \
  --output run.beir.bm25-flat.fiqa.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fiqa-test \
  run.beir.bm25-flat.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fiqa-test \
  run.beir.bm25-flat.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fiqa-test \
  run.beir.bm25-flat.fiqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row6-tab2" role="tabpanel" aria-labelledby="row6-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-fiqa.multifield \
  --topics beir-v1.0.0-fiqa-test \
  --output run.beir.bm25-multifield.fiqa.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fiqa-test \
  run.beir.bm25-multifield.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fiqa-test \
  run.beir.bm25-multifield.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fiqa-test \
  run.beir.bm25-multifield.fiqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row6-tab3" role="tabpanel" aria-labelledby="row6-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-fiqa.splade-pp-ed \
  --topics beir-v1.0.0-fiqa.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.fiqa.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fiqa-test \
  run.beir.splade-pp-ed.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fiqa-test \
  run.beir.splade-pp-ed.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fiqa-test \
  run.beir.splade-pp-ed.fiqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row6-tab4" role="tabpanel" aria-labelledby="row6-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-fiqa.contriever-msmarco \
  --topics beir-v1.0.0-fiqa-test \
  --output run.beir.contriever-msmarco.fiqa.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fiqa-test \
  run.beir.contriever-msmarco.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fiqa-test \
  run.beir.contriever-msmarco.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fiqa-test \
  run.beir.contriever-msmarco.fiqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row6-tab5" role="tabpanel" aria-labelledby="row6-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-fiqa.bge-base-en-v1.5 \
  --topics beir-v1.0.0-fiqa-test \
  --output run.beir.bge-base-en-v1.5.fiqa.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fiqa-test \
  run.beir.bge-base-en-v1.5.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fiqa-test \
  run.beir.bge-base-en-v1.5.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fiqa-test \
  run.beir.bge-base-en-v1.5.fiqa.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row6-tab6" role="tabpanel" aria-labelledby="row6-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-fiqa.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-fiqa-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-fiqa-test \
  --output run.beir.cohere-embed-english-v3.0.fiqa.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fiqa-test \
  run.beir.cohere-embed-english-v3.0.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fiqa-test \
  run.beir.cohere-embed-english-v3.0.fiqa.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fiqa-test \
  run.beir.cohere-embed-english-v3.0.fiqa.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: signal1m -->
<tr class="accordion-toggle collapsed" id="row7" data-toggle="collapse" data-parent="#row7" href="#collapse7">
<td class="expand-button"></td>
<td>signal1m</td>
<td>  0.3304</td>
<td>  0.3703</td>
<td></td>
<td>  0.3304</td>
<td>  0.3703</td>
<td></td>
<td>  0.3008</td>
<td>  0.3398</td>
<td></td>
<td>  0.2783</td>
<td>  0.3220</td>
<td></td>
<td>  0.2886</td>
<td>  0.3112</td>
<td></td>
<td>  0.2632</td>
<td>  0.2832</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse7" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row7-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row7-tab1-header" data-mdb-toggle="tab" href="#row7-tab1" role="tab" aria-controls="row7-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row7-tab2-header" data-mdb-toggle="tab" href="#row7-tab2" role="tab" aria-controls="row7-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row7-tab3-header" data-mdb-toggle="tab" href="#row7-tab3" role="tab" aria-controls="row7-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row7-tab4-header" data-mdb-toggle="tab" href="#row7-tab4" role="tab" aria-controls="row7-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row7-tab5-header" data-mdb-toggle="tab" href="#row7-tab5" role="tab" aria-controls="row7-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row7-tab6-header" data-mdb-toggle="tab" href="#row7-tab6" role="tab" aria-controls="row7-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row7-content">
  <div class="tab-pane fade show active" id="row7-tab1" role="tabpanel" aria-labelledby="row7-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-signal1m.flat \
  --topics beir-v1.0.0-signal1m-test \
  --output run.beir.bm25-flat.signal1m.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-signal1m-test \
  run.beir.bm25-flat.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-signal1m-test \
  run.beir.bm25-flat.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-signal1m-test \
  run.beir.bm25-flat.signal1m.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row7-tab2" role="tabpanel" aria-labelledby="row7-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-signal1m.multifield \
  --topics beir-v1.0.0-signal1m-test \
  --output run.beir.bm25-multifield.signal1m.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-signal1m-test \
  run.beir.bm25-multifield.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-signal1m-test \
  run.beir.bm25-multifield.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-signal1m-test \
  run.beir.bm25-multifield.signal1m.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row7-tab3" role="tabpanel" aria-labelledby="row7-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-signal1m.splade-pp-ed \
  --topics beir-v1.0.0-signal1m.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.signal1m.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-signal1m-test \
  run.beir.splade-pp-ed.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-signal1m-test \
  run.beir.splade-pp-ed.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-signal1m-test \
  run.beir.splade-pp-ed.signal1m.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row7-tab4" role="tabpanel" aria-labelledby="row7-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-signal1m.contriever-msmarco \
  --topics beir-v1.0.0-signal1m-test \
  --output run.beir.contriever-msmarco.signal1m.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-signal1m-test \
  run.beir.contriever-msmarco.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-signal1m-test \
  run.beir.contriever-msmarco.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-signal1m-test \
  run.beir.contriever-msmarco.signal1m.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row7-tab5" role="tabpanel" aria-labelledby="row7-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-signal1m.bge-base-en-v1.5 \
  --topics beir-v1.0.0-signal1m-test \
  --output run.beir.bge-base-en-v1.5.signal1m.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-signal1m-test \
  run.beir.bge-base-en-v1.5.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-signal1m-test \
  run.beir.bge-base-en-v1.5.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-signal1m-test \
  run.beir.bge-base-en-v1.5.signal1m.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row7-tab6" role="tabpanel" aria-labelledby="row7-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-signal1m.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-signal1m-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-signal1m-test \
  --output run.beir.cohere-embed-english-v3.0.signal1m.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-signal1m-test \
  run.beir.cohere-embed-english-v3.0.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-signal1m-test \
  run.beir.cohere-embed-english-v3.0.signal1m.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-signal1m-test \
  run.beir.cohere-embed-english-v3.0.signal1m.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: trec-news -->
<tr class="accordion-toggle collapsed" id="row8" data-toggle="collapse" data-parent="#row8" href="#collapse8">
<td class="expand-button"></td>
<td>trec-news</td>
<td>  0.3952</td>
<td>  0.4469</td>
<td></td>
<td>  0.3977</td>
<td>  0.4216</td>
<td></td>
<td>  0.4152</td>
<td>  0.4414</td>
<td></td>
<td>  0.4283</td>
<td>  0.4924</td>
<td></td>
<td>  0.4424</td>
<td>  0.4992</td>
<td></td>
<td>  0.5042</td>
<td>  0.5431</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse8" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row8-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row8-tab1-header" data-mdb-toggle="tab" href="#row8-tab1" role="tab" aria-controls="row8-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row8-tab2-header" data-mdb-toggle="tab" href="#row8-tab2" role="tab" aria-controls="row8-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row8-tab3-header" data-mdb-toggle="tab" href="#row8-tab3" role="tab" aria-controls="row8-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row8-tab4-header" data-mdb-toggle="tab" href="#row8-tab4" role="tab" aria-controls="row8-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row8-tab5-header" data-mdb-toggle="tab" href="#row8-tab5" role="tab" aria-controls="row8-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row8-tab6-header" data-mdb-toggle="tab" href="#row8-tab6" role="tab" aria-controls="row8-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row8-content">
  <div class="tab-pane fade show active" id="row8-tab1" role="tabpanel" aria-labelledby="row8-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-trec-news.flat \
  --topics beir-v1.0.0-trec-news-test \
  --output run.beir.bm25-flat.trec-news.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-news-test \
  run.beir.bm25-flat.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-news-test \
  run.beir.bm25-flat.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-news-test \
  run.beir.bm25-flat.trec-news.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row8-tab2" role="tabpanel" aria-labelledby="row8-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-trec-news.multifield \
  --topics beir-v1.0.0-trec-news-test \
  --output run.beir.bm25-multifield.trec-news.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-news-test \
  run.beir.bm25-multifield.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-news-test \
  run.beir.bm25-multifield.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-news-test \
  run.beir.bm25-multifield.trec-news.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row8-tab3" role="tabpanel" aria-labelledby="row8-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-trec-news.splade-pp-ed \
  --topics beir-v1.0.0-trec-news.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.trec-news.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-news-test \
  run.beir.splade-pp-ed.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-news-test \
  run.beir.splade-pp-ed.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-news-test \
  run.beir.splade-pp-ed.trec-news.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row8-tab4" role="tabpanel" aria-labelledby="row8-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-trec-news.contriever-msmarco \
  --topics beir-v1.0.0-trec-news-test \
  --output run.beir.contriever-msmarco.trec-news.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-news-test \
  run.beir.contriever-msmarco.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-news-test \
  run.beir.contriever-msmarco.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-news-test \
  run.beir.contriever-msmarco.trec-news.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row8-tab5" role="tabpanel" aria-labelledby="row8-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-trec-news.bge-base-en-v1.5 \
  --topics beir-v1.0.0-trec-news-test \
  --output run.beir.bge-base-en-v1.5.trec-news.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-news-test \
  run.beir.bge-base-en-v1.5.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-news-test \
  run.beir.bge-base-en-v1.5.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-news-test \
  run.beir.bge-base-en-v1.5.trec-news.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row8-tab6" role="tabpanel" aria-labelledby="row8-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-trec-news.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-trec-news-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-trec-news-test \
  --output run.beir.cohere-embed-english-v3.0.trec-news.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-trec-news-test \
  run.beir.cohere-embed-english-v3.0.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-trec-news-test \
  run.beir.cohere-embed-english-v3.0.trec-news.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-trec-news-test \
  run.beir.cohere-embed-english-v3.0.trec-news.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: robust04 -->
<tr class="accordion-toggle collapsed" id="row9" data-toggle="collapse" data-parent="#row9" href="#collapse9">
<td class="expand-button"></td>
<td>robust04</td>
<td>  0.4070</td>
<td>  0.3746</td>
<td></td>
<td>  0.4070</td>
<td>  0.3746</td>
<td></td>
<td>  0.4679</td>
<td>  0.3850</td>
<td></td>
<td>  0.4729</td>
<td>  0.3917</td>
<td></td>
<td>  0.4435</td>
<td>  0.3510</td>
<td></td>
<td>  0.5406</td>
<td>  0.4171</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse9" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row9-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row9-tab1-header" data-mdb-toggle="tab" href="#row9-tab1" role="tab" aria-controls="row9-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row9-tab2-header" data-mdb-toggle="tab" href="#row9-tab2" role="tab" aria-controls="row9-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row9-tab3-header" data-mdb-toggle="tab" href="#row9-tab3" role="tab" aria-controls="row9-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row9-tab4-header" data-mdb-toggle="tab" href="#row9-tab4" role="tab" aria-controls="row9-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row9-tab5-header" data-mdb-toggle="tab" href="#row9-tab5" role="tab" aria-controls="row9-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row9-tab6-header" data-mdb-toggle="tab" href="#row9-tab6" role="tab" aria-controls="row9-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row9-content">
  <div class="tab-pane fade show active" id="row9-tab1" role="tabpanel" aria-labelledby="row9-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-robust04.flat \
  --topics beir-v1.0.0-robust04-test \
  --output run.beir.bm25-flat.robust04.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-robust04-test \
  run.beir.bm25-flat.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-robust04-test \
  run.beir.bm25-flat.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-robust04-test \
  run.beir.bm25-flat.robust04.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row9-tab2" role="tabpanel" aria-labelledby="row9-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-robust04.multifield \
  --topics beir-v1.0.0-robust04-test \
  --output run.beir.bm25-multifield.robust04.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-robust04-test \
  run.beir.bm25-multifield.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-robust04-test \
  run.beir.bm25-multifield.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-robust04-test \
  run.beir.bm25-multifield.robust04.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row9-tab3" role="tabpanel" aria-labelledby="row9-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-robust04.splade-pp-ed \
  --topics beir-v1.0.0-robust04.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.robust04.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-robust04-test \
  run.beir.splade-pp-ed.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-robust04-test \
  run.beir.splade-pp-ed.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-robust04-test \
  run.beir.splade-pp-ed.robust04.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row9-tab4" role="tabpanel" aria-labelledby="row9-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-robust04.contriever-msmarco \
  --topics beir-v1.0.0-robust04-test \
  --output run.beir.contriever-msmarco.robust04.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-robust04-test \
  run.beir.contriever-msmarco.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-robust04-test \
  run.beir.contriever-msmarco.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-robust04-test \
  run.beir.contriever-msmarco.robust04.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row9-tab5" role="tabpanel" aria-labelledby="row9-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-robust04.bge-base-en-v1.5 \
  --topics beir-v1.0.0-robust04-test \
  --output run.beir.bge-base-en-v1.5.robust04.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-robust04-test \
  run.beir.bge-base-en-v1.5.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-robust04-test \
  run.beir.bge-base-en-v1.5.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-robust04-test \
  run.beir.bge-base-en-v1.5.robust04.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row9-tab6" role="tabpanel" aria-labelledby="row9-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-robust04.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-robust04-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-robust04-test \
  --output run.beir.cohere-embed-english-v3.0.robust04.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-robust04-test \
  run.beir.cohere-embed-english-v3.0.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-robust04-test \
  run.beir.cohere-embed-english-v3.0.robust04.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-robust04-test \
  run.beir.cohere-embed-english-v3.0.robust04.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: arguana -->
<tr class="accordion-toggle collapsed" id="row10" data-toggle="collapse" data-parent="#row10" href="#collapse10">
<td class="expand-button"></td>
<td>arguana</td>
<td>  0.3970</td>
<td>  0.9324</td>
<td></td>
<td>  0.4142</td>
<td>  0.9431</td>
<td></td>
<td>  0.5203</td>
<td>  0.9744</td>
<td></td>
<td>  0.4461</td>
<td>  0.9765</td>
<td></td>
<td>  0.6362</td>
<td>  0.9915</td>
<td></td>
<td>  0.5398</td>
<td>  0.9815</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse10" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row10-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row10-tab1-header" data-mdb-toggle="tab" href="#row10-tab1" role="tab" aria-controls="row10-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row10-tab2-header" data-mdb-toggle="tab" href="#row10-tab2" role="tab" aria-controls="row10-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row10-tab3-header" data-mdb-toggle="tab" href="#row10-tab3" role="tab" aria-controls="row10-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row10-tab4-header" data-mdb-toggle="tab" href="#row10-tab4" role="tab" aria-controls="row10-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row10-tab5-header" data-mdb-toggle="tab" href="#row10-tab5" role="tab" aria-controls="row10-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row10-tab6-header" data-mdb-toggle="tab" href="#row10-tab6" role="tab" aria-controls="row10-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row10-content">
  <div class="tab-pane fade show active" id="row10-tab1" role="tabpanel" aria-labelledby="row10-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-arguana.flat \
  --topics beir-v1.0.0-arguana-test \
  --output run.beir.bm25-flat.arguana.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-arguana-test \
  run.beir.bm25-flat.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-arguana-test \
  run.beir.bm25-flat.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-arguana-test \
  run.beir.bm25-flat.arguana.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row10-tab2" role="tabpanel" aria-labelledby="row10-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-arguana.multifield \
  --topics beir-v1.0.0-arguana-test \
  --output run.beir.bm25-multifield.arguana.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-arguana-test \
  run.beir.bm25-multifield.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-arguana-test \
  run.beir.bm25-multifield.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-arguana-test \
  run.beir.bm25-multifield.arguana.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row10-tab3" role="tabpanel" aria-labelledby="row10-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-arguana.splade-pp-ed \
  --topics beir-v1.0.0-arguana.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.arguana.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-arguana-test \
  run.beir.splade-pp-ed.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-arguana-test \
  run.beir.splade-pp-ed.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-arguana-test \
  run.beir.splade-pp-ed.arguana.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row10-tab4" role="tabpanel" aria-labelledby="row10-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-arguana.contriever-msmarco \
  --topics beir-v1.0.0-arguana-test \
  --output run.beir.contriever-msmarco.arguana.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-arguana-test \
  run.beir.contriever-msmarco.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-arguana-test \
  run.beir.contriever-msmarco.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-arguana-test \
  run.beir.contriever-msmarco.arguana.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row10-tab5" role="tabpanel" aria-labelledby="row10-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "" \
  --index beir-v1.0.0-arguana.bge-base-en-v1.5 \
  --topics beir-v1.0.0-arguana-test \
  --output run.beir.bge-base-en-v1.5.arguana.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-arguana-test \
  run.beir.bge-base-en-v1.5.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-arguana-test \
  run.beir.bge-base-en-v1.5.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-arguana-test \
  run.beir.bge-base-en-v1.5.arguana.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row10-tab6" role="tabpanel" aria-labelledby="row10-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-arguana.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-arguana-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-arguana-test \
  --output run.beir.cohere-embed-english-v3.0.arguana.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-arguana-test \
  run.beir.cohere-embed-english-v3.0.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-arguana-test \
  run.beir.cohere-embed-english-v3.0.arguana.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-arguana-test \
  run.beir.cohere-embed-english-v3.0.arguana.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: webis-touche2020 -->
<tr class="accordion-toggle collapsed" id="row11" data-toggle="collapse" data-parent="#row11" href="#collapse11">
<td class="expand-button"></td>
<td>webis-touche2020</td>
<td>  0.4422</td>
<td>  0.5822</td>
<td></td>
<td>  0.3673</td>
<td>  0.5376</td>
<td></td>
<td>  0.2468</td>
<td>  0.4715</td>
<td></td>
<td>  0.2040</td>
<td>  0.4420</td>
<td></td>
<td>  0.2571</td>
<td>  0.4867</td>
<td></td>
<td>  0.3264</td>
<td>  0.5157</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse11" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row11-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row11-tab1-header" data-mdb-toggle="tab" href="#row11-tab1" role="tab" aria-controls="row11-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row11-tab2-header" data-mdb-toggle="tab" href="#row11-tab2" role="tab" aria-controls="row11-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row11-tab3-header" data-mdb-toggle="tab" href="#row11-tab3" role="tab" aria-controls="row11-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row11-tab4-header" data-mdb-toggle="tab" href="#row11-tab4" role="tab" aria-controls="row11-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row11-tab5-header" data-mdb-toggle="tab" href="#row11-tab5" role="tab" aria-controls="row11-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row11-tab6-header" data-mdb-toggle="tab" href="#row11-tab6" role="tab" aria-controls="row11-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row11-content">
  <div class="tab-pane fade show active" id="row11-tab1" role="tabpanel" aria-labelledby="row11-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-webis-touche2020.flat \
  --topics beir-v1.0.0-webis-touche2020-test \
  --output run.beir.bm25-flat.webis-touche2020.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-webis-touche2020-test \
  run.beir.bm25-flat.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-webis-touche2020-test \
  run.beir.bm25-flat.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-webis-touche2020-test \
  run.beir.bm25-flat.webis-touche2020.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row11-tab2" role="tabpanel" aria-labelledby="row11-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-webis-touche2020.multifield \
  --topics beir-v1.0.0-webis-touche2020-test \
  --output run.beir.bm25-multifield.webis-touche2020.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-webis-touche2020-test \
  run.beir.bm25-multifield.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-webis-touche2020-test \
  run.beir.bm25-multifield.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-webis-touche2020-test \
  run.beir.bm25-multifield.webis-touche2020.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row11-tab3" role="tabpanel" aria-labelledby="row11-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-webis-touche2020.splade-pp-ed \
  --topics beir-v1.0.0-webis-touche2020.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.webis-touche2020.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-webis-touche2020-test \
  run.beir.splade-pp-ed.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-webis-touche2020-test \
  run.beir.splade-pp-ed.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-webis-touche2020-test \
  run.beir.splade-pp-ed.webis-touche2020.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row11-tab4" role="tabpanel" aria-labelledby="row11-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-webis-touche2020.contriever-msmarco \
  --topics beir-v1.0.0-webis-touche2020-test \
  --output run.beir.contriever-msmarco.webis-touche2020.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-webis-touche2020-test \
  run.beir.contriever-msmarco.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-webis-touche2020-test \
  run.beir.contriever-msmarco.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-webis-touche2020-test \
  run.beir.contriever-msmarco.webis-touche2020.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row11-tab5" role="tabpanel" aria-labelledby="row11-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-webis-touche2020.bge-base-en-v1.5 \
  --topics beir-v1.0.0-webis-touche2020-test \
  --output run.beir.bge-base-en-v1.5.webis-touche2020.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-webis-touche2020-test \
  run.beir.bge-base-en-v1.5.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-webis-touche2020-test \
  run.beir.bge-base-en-v1.5.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-webis-touche2020-test \
  run.beir.bge-base-en-v1.5.webis-touche2020.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row11-tab6" role="tabpanel" aria-labelledby="row11-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-webis-touche2020.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-webis-touche2020-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-webis-touche2020-test \
  --output run.beir.cohere-embed-english-v3.0.webis-touche2020.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-webis-touche2020-test \
  run.beir.cohere-embed-english-v3.0.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-webis-touche2020-test \
  run.beir.cohere-embed-english-v3.0.webis-touche2020.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-webis-touche2020-test \
  run.beir.cohere-embed-english-v3.0.webis-touche2020.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack (average) -->
<tr class="accordion-toggle collapsed" id="row24" data-toggle="collapse" data-parent="#row24" href="#collapse24">
<td class="expand-button"></td>
<td>cqadupstack (average)</td>
<td>  0.3021</td>
<td>  0.5797</td>
<td></td>
<td>  0.2987</td>
<td>  0.6056</td>
<td></td>
<td>  0.3338</td>
<td>  0.6496</td>
<td></td>
<td>  0.3454</td>
<td>  0.6628</td>
<td></td>
<td>  0.4237</td>
<td>  0.7621</td>
<td></td>
<td>  0.4152</td>
<td>  0.7447</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse24" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row24-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row24-tab1-header" data-mdb-toggle="tab" href="#row24-tab1" role="tab" aria-controls="row24-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab2-header" data-mdb-toggle="tab" href="#row24-tab2" role="tab" aria-controls="row24-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab3-header" data-mdb-toggle="tab" href="#row24-tab3" role="tab" aria-controls="row24-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab4-header" data-mdb-toggle="tab" href="#row24-tab4" role="tab" aria-controls="row24-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab5-header" data-mdb-toggle="tab" href="#row24-tab5" role="tab" aria-controls="row24-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab6-header" data-mdb-toggle="tab" href="#row24-tab6" role="tab" aria-controls="row24-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row24-content">
  <div class="tab-pane fade show active" id="row24-tab1" role="tabpanel" aria-labelledby="row24-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-android.flat \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.bm25-flat.cqadupstack-android.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-english.flat \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.bm25-flat.cqadupstack-english.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gaming.flat \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.bm25-flat.cqadupstack-gaming.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gis.flat \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.bm25-flat.cqadupstack-gis.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-mathematica.flat \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.bm25-flat.cqadupstack-mathematica.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-physics.flat \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.bm25-flat.cqadupstack-physics.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-programmers.flat \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.bm25-flat.cqadupstack-programmers.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-stats.flat \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.bm25-flat.cqadupstack-stats.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-tex.flat \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.bm25-flat.cqadupstack-tex.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-unix.flat \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.bm25-flat.cqadupstack-unix.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-webmasters.flat \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.bm25-flat.cqadupstack-webmasters.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-wordpress.flat \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.bm25-flat.cqadupstack-wordpress.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query


</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab2" role="tabpanel" aria-labelledby="row24-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-android.multifield \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.bm25-multifield.cqadupstack-android.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-english.multifield \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.bm25-multifield.cqadupstack-english.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gaming.multifield \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.bm25-multifield.cqadupstack-gaming.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gis.multifield \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.bm25-multifield.cqadupstack-gis.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-mathematica.multifield \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.bm25-multifield.cqadupstack-mathematica.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-physics.multifield \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.bm25-multifield.cqadupstack-physics.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-programmers.multifield \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.bm25-multifield.cqadupstack-programmers.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-stats.multifield \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.bm25-multifield.cqadupstack-stats.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-tex.multifield \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.bm25-multifield.cqadupstack-tex.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-unix.multifield \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.bm25-multifield.cqadupstack-unix.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-webmasters.multifield \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.bm25-multifield.cqadupstack-webmasters.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-wordpress.multifield \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.bm25-multifield.cqadupstack-wordpress.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0


</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab3" role="tabpanel" aria-labelledby="row24-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-android.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-android.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-android.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-english.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-english.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-english.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gaming.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-gaming.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-gaming.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gis.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-gis.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-gis.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-mathematica.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-mathematica.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-mathematica.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-physics.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-physics.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-physics.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-programmers.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-programmers.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-programmers.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-stats.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-stats.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-stats.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-tex.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-tex.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-tex.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-unix.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-unix.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-unix.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-webmasters.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-webmasters.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-webmasters.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query

python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-wordpress.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-wordpress.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-wordpress.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query


</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab4" role="tabpanel" aria-labelledby="row24-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-android.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.contriever-msmarco.cqadupstack-android.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-english.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.contriever-msmarco.cqadupstack-english.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-gaming.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.contriever-msmarco.cqadupstack-gaming.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-gis.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.contriever-msmarco.cqadupstack-gis.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-mathematica.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.contriever-msmarco.cqadupstack-mathematica.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-physics.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.contriever-msmarco.cqadupstack-physics.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-programmers.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.contriever-msmarco.cqadupstack-programmers.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-stats.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.contriever-msmarco.cqadupstack-stats.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-tex.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.contriever-msmarco.cqadupstack-tex.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-unix.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.contriever-msmarco.cqadupstack-unix.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-webmasters.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.contriever-msmarco.cqadupstack-webmasters.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-wordpress.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.contriever-msmarco.cqadupstack-wordpress.txt \
  --hits 1000 --remove-query


</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab5" role="tabpanel" aria-labelledby="row24-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-android.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-android.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-english.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-english.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-gaming.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-gis.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-gis.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-mathematica.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-physics.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-physics.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-programmers.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-stats.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-stats.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-tex.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-tex.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-unix.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-unix.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-webmasters.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-wordpress.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt \
  --hits 1000 --remove-query


</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab6" role="tabpanel" aria-labelledby="row24-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-android.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-android-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-english.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-english-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-gaming.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-gaming-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-gis.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-gis-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-mathematica.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-mathematica-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-physics.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-physics-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-programmers.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-programmers-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-stats.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-stats-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-tex.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-tex-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-unix.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-unix-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-webmasters.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-webmasters-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt \
  --hits 1000 --remove-query

python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-wordpress.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-wordpress-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt \
  --hits 1000 --remove-query


</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: quora -->
<tr class="accordion-toggle collapsed" id="row24" data-toggle="collapse" data-parent="#row24" href="#collapse24">
<td class="expand-button"></td>
<td>quora</td>
<td>  0.7886</td>
<td>  0.9733</td>
<td></td>
<td>  0.7886</td>
<td>  0.9733</td>
<td></td>
<td>  0.8343</td>
<td>  0.9863</td>
<td></td>
<td>  0.8648</td>
<td>  0.9935</td>
<td></td>
<td>  0.8890</td>
<td>  0.9968</td>
<td></td>
<td>  0.8872</td>
<td>  0.9962</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse24" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row24-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row24-tab1-header" data-mdb-toggle="tab" href="#row24-tab1" role="tab" aria-controls="row24-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab2-header" data-mdb-toggle="tab" href="#row24-tab2" role="tab" aria-controls="row24-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab3-header" data-mdb-toggle="tab" href="#row24-tab3" role="tab" aria-controls="row24-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab4-header" data-mdb-toggle="tab" href="#row24-tab4" role="tab" aria-controls="row24-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab5-header" data-mdb-toggle="tab" href="#row24-tab5" role="tab" aria-controls="row24-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row24-tab6-header" data-mdb-toggle="tab" href="#row24-tab6" role="tab" aria-controls="row24-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row24-content">
  <div class="tab-pane fade show active" id="row24-tab1" role="tabpanel" aria-labelledby="row24-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-quora.flat \
  --topics beir-v1.0.0-quora-test \
  --output run.beir.bm25-flat.quora.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-quora-test \
  run.beir.bm25-flat.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-quora-test \
  run.beir.bm25-flat.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-quora-test \
  run.beir.bm25-flat.quora.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab2" role="tabpanel" aria-labelledby="row24-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-quora.multifield \
  --topics beir-v1.0.0-quora-test \
  --output run.beir.bm25-multifield.quora.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-quora-test \
  run.beir.bm25-multifield.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-quora-test \
  run.beir.bm25-multifield.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-quora-test \
  run.beir.bm25-multifield.quora.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab3" role="tabpanel" aria-labelledby="row24-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-quora.splade-pp-ed \
  --topics beir-v1.0.0-quora.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.quora.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-quora-test \
  run.beir.splade-pp-ed.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-quora-test \
  run.beir.splade-pp-ed.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-quora-test \
  run.beir.splade-pp-ed.quora.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab4" role="tabpanel" aria-labelledby="row24-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-quora.contriever-msmarco \
  --topics beir-v1.0.0-quora-test \
  --output run.beir.contriever-msmarco.quora.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-quora-test \
  run.beir.contriever-msmarco.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-quora-test \
  run.beir.contriever-msmarco.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-quora-test \
  run.beir.contriever-msmarco.quora.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab5" role="tabpanel" aria-labelledby="row24-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "" \
  --index beir-v1.0.0-quora.bge-base-en-v1.5 \
  --topics beir-v1.0.0-quora-test \
  --output run.beir.bge-base-en-v1.5.quora.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-quora-test \
  run.beir.bge-base-en-v1.5.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-quora-test \
  run.beir.bge-base-en-v1.5.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-quora-test \
  run.beir.bge-base-en-v1.5.quora.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row24-tab6" role="tabpanel" aria-labelledby="row24-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-quora.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-quora-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-quora-test \
  --output run.beir.cohere-embed-english-v3.0.quora.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-quora-test \
  run.beir.cohere-embed-english-v3.0.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-quora-test \
  run.beir.cohere-embed-english-v3.0.quora.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-quora-test \
  run.beir.cohere-embed-english-v3.0.quora.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: dbpedia-entity -->
<tr class="accordion-toggle collapsed" id="row26" data-toggle="collapse" data-parent="#row26" href="#collapse26">
<td class="expand-button"></td>
<td>dbpedia-entity</td>
<td>  0.3180</td>
<td>  0.4682</td>
<td></td>
<td>  0.3128</td>
<td>  0.3981</td>
<td></td>
<td>  0.4366</td>
<td>  0.5624</td>
<td></td>
<td>  0.4128</td>
<td>  0.5414</td>
<td></td>
<td>  0.4073</td>
<td>  0.5298</td>
<td></td>
<td>  0.4340</td>
<td>  0.5358</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse26" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row26-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row26-tab1-header" data-mdb-toggle="tab" href="#row26-tab1" role="tab" aria-controls="row26-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row26-tab2-header" data-mdb-toggle="tab" href="#row26-tab2" role="tab" aria-controls="row26-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row26-tab3-header" data-mdb-toggle="tab" href="#row26-tab3" role="tab" aria-controls="row26-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row26-tab4-header" data-mdb-toggle="tab" href="#row26-tab4" role="tab" aria-controls="row26-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row26-tab5-header" data-mdb-toggle="tab" href="#row26-tab5" role="tab" aria-controls="row26-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row26-tab6-header" data-mdb-toggle="tab" href="#row26-tab6" role="tab" aria-controls="row26-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row26-content">
  <div class="tab-pane fade show active" id="row26-tab1" role="tabpanel" aria-labelledby="row26-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-dbpedia-entity.flat \
  --topics beir-v1.0.0-dbpedia-entity-test \
  --output run.beir.bm25-flat.dbpedia-entity.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bm25-flat.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bm25-flat.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bm25-flat.dbpedia-entity.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row26-tab2" role="tabpanel" aria-labelledby="row26-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-dbpedia-entity.multifield \
  --topics beir-v1.0.0-dbpedia-entity-test \
  --output run.beir.bm25-multifield.dbpedia-entity.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bm25-multifield.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bm25-multifield.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bm25-multifield.dbpedia-entity.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row26-tab3" role="tabpanel" aria-labelledby="row26-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-dbpedia-entity.splade-pp-ed \
  --topics beir-v1.0.0-dbpedia-entity.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.dbpedia-entity.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-dbpedia-entity-test \
  run.beir.splade-pp-ed.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-dbpedia-entity-test \
  run.beir.splade-pp-ed.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-dbpedia-entity-test \
  run.beir.splade-pp-ed.dbpedia-entity.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row26-tab4" role="tabpanel" aria-labelledby="row26-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-dbpedia-entity.contriever-msmarco \
  --topics beir-v1.0.0-dbpedia-entity-test \
  --output run.beir.contriever-msmarco.dbpedia-entity.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-dbpedia-entity-test \
  run.beir.contriever-msmarco.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-dbpedia-entity-test \
  run.beir.contriever-msmarco.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-dbpedia-entity-test \
  run.beir.contriever-msmarco.dbpedia-entity.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row26-tab5" role="tabpanel" aria-labelledby="row26-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-dbpedia-entity.bge-base-en-v1.5 \
  --topics beir-v1.0.0-dbpedia-entity-test \
  --output run.beir.bge-base-en-v1.5.dbpedia-entity.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bge-base-en-v1.5.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bge-base-en-v1.5.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-dbpedia-entity-test \
  run.beir.bge-base-en-v1.5.dbpedia-entity.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row26-tab6" role="tabpanel" aria-labelledby="row26-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-dbpedia-entity.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-dbpedia-entity-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-dbpedia-entity-test \
  --output run.beir.cohere-embed-english-v3.0.dbpedia-entity.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-dbpedia-entity-test \
  run.beir.cohere-embed-english-v3.0.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-dbpedia-entity-test \
  run.beir.cohere-embed-english-v3.0.dbpedia-entity.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-dbpedia-entity-test \
  run.beir.cohere-embed-english-v3.0.dbpedia-entity.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: scidocs -->
<tr class="accordion-toggle collapsed" id="row27" data-toggle="collapse" data-parent="#row27" href="#collapse27">
<td class="expand-button"></td>
<td>scidocs</td>
<td>  0.1490</td>
<td>  0.3477</td>
<td></td>
<td>  0.1581</td>
<td>  0.3561</td>
<td></td>
<td>  0.1591</td>
<td>  0.3730</td>
<td></td>
<td>  0.1652</td>
<td>  0.3783</td>
<td></td>
<td>  0.2172</td>
<td>  0.4959</td>
<td></td>
<td>  0.2034</td>
<td>  0.4509</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse27" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row27-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row27-tab1-header" data-mdb-toggle="tab" href="#row27-tab1" role="tab" aria-controls="row27-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row27-tab2-header" data-mdb-toggle="tab" href="#row27-tab2" role="tab" aria-controls="row27-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row27-tab3-header" data-mdb-toggle="tab" href="#row27-tab3" role="tab" aria-controls="row27-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row27-tab4-header" data-mdb-toggle="tab" href="#row27-tab4" role="tab" aria-controls="row27-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row27-tab5-header" data-mdb-toggle="tab" href="#row27-tab5" role="tab" aria-controls="row27-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row27-tab6-header" data-mdb-toggle="tab" href="#row27-tab6" role="tab" aria-controls="row27-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row27-content">
  <div class="tab-pane fade show active" id="row27-tab1" role="tabpanel" aria-labelledby="row27-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-scidocs.flat \
  --topics beir-v1.0.0-scidocs-test \
  --output run.beir.bm25-flat.scidocs.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scidocs-test \
  run.beir.bm25-flat.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scidocs-test \
  run.beir.bm25-flat.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scidocs-test \
  run.beir.bm25-flat.scidocs.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row27-tab2" role="tabpanel" aria-labelledby="row27-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-scidocs.multifield \
  --topics beir-v1.0.0-scidocs-test \
  --output run.beir.bm25-multifield.scidocs.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scidocs-test \
  run.beir.bm25-multifield.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scidocs-test \
  run.beir.bm25-multifield.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scidocs-test \
  run.beir.bm25-multifield.scidocs.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row27-tab3" role="tabpanel" aria-labelledby="row27-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-scidocs.splade-pp-ed \
  --topics beir-v1.0.0-scidocs.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.scidocs.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scidocs-test \
  run.beir.splade-pp-ed.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scidocs-test \
  run.beir.splade-pp-ed.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scidocs-test \
  run.beir.splade-pp-ed.scidocs.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row27-tab4" role="tabpanel" aria-labelledby="row27-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-scidocs.contriever-msmarco \
  --topics beir-v1.0.0-scidocs-test \
  --output run.beir.contriever-msmarco.scidocs.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scidocs-test \
  run.beir.contriever-msmarco.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scidocs-test \
  run.beir.contriever-msmarco.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scidocs-test \
  run.beir.contriever-msmarco.scidocs.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row27-tab5" role="tabpanel" aria-labelledby="row27-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-scidocs.bge-base-en-v1.5 \
  --topics beir-v1.0.0-scidocs-test \
  --output run.beir.bge-base-en-v1.5.scidocs.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scidocs-test \
  run.beir.bge-base-en-v1.5.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scidocs-test \
  run.beir.bge-base-en-v1.5.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scidocs-test \
  run.beir.bge-base-en-v1.5.scidocs.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row27-tab6" role="tabpanel" aria-labelledby="row27-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-scidocs.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-scidocs-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-scidocs-test \
  --output run.beir.cohere-embed-english-v3.0.scidocs.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scidocs-test \
  run.beir.cohere-embed-english-v3.0.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scidocs-test \
  run.beir.cohere-embed-english-v3.0.scidocs.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scidocs-test \
  run.beir.cohere-embed-english-v3.0.scidocs.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: fever -->
<tr class="accordion-toggle collapsed" id="row28" data-toggle="collapse" data-parent="#row28" href="#collapse28">
<td class="expand-button"></td>
<td>fever</td>
<td>  0.6513</td>
<td>  0.9185</td>
<td></td>
<td>  0.7530</td>
<td>  0.9309</td>
<td></td>
<td>  0.7882</td>
<td>  0.9459</td>
<td></td>
<td>  0.7583</td>
<td>  0.9494</td>
<td></td>
<td>  0.8629</td>
<td>  0.9719</td>
<td></td>
<td>  0.8900</td>
<td>  0.9649</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse28" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row28-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row28-tab1-header" data-mdb-toggle="tab" href="#row28-tab1" role="tab" aria-controls="row28-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row28-tab2-header" data-mdb-toggle="tab" href="#row28-tab2" role="tab" aria-controls="row28-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row28-tab3-header" data-mdb-toggle="tab" href="#row28-tab3" role="tab" aria-controls="row28-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row28-tab4-header" data-mdb-toggle="tab" href="#row28-tab4" role="tab" aria-controls="row28-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row28-tab5-header" data-mdb-toggle="tab" href="#row28-tab5" role="tab" aria-controls="row28-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row28-tab6-header" data-mdb-toggle="tab" href="#row28-tab6" role="tab" aria-controls="row28-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row28-content">
  <div class="tab-pane fade show active" id="row28-tab1" role="tabpanel" aria-labelledby="row28-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-fever.flat \
  --topics beir-v1.0.0-fever-test \
  --output run.beir.bm25-flat.fever.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fever-test \
  run.beir.bm25-flat.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fever-test \
  run.beir.bm25-flat.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fever-test \
  run.beir.bm25-flat.fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row28-tab2" role="tabpanel" aria-labelledby="row28-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-fever.multifield \
  --topics beir-v1.0.0-fever-test \
  --output run.beir.bm25-multifield.fever.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fever-test \
  run.beir.bm25-multifield.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fever-test \
  run.beir.bm25-multifield.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fever-test \
  run.beir.bm25-multifield.fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row28-tab3" role="tabpanel" aria-labelledby="row28-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-fever.splade-pp-ed \
  --topics beir-v1.0.0-fever.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.fever.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fever-test \
  run.beir.splade-pp-ed.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fever-test \
  run.beir.splade-pp-ed.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fever-test \
  run.beir.splade-pp-ed.fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row28-tab4" role="tabpanel" aria-labelledby="row28-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-fever.contriever-msmarco \
  --topics beir-v1.0.0-fever-test \
  --output run.beir.contriever-msmarco.fever.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fever-test \
  run.beir.contriever-msmarco.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fever-test \
  run.beir.contriever-msmarco.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fever-test \
  run.beir.contriever-msmarco.fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row28-tab5" role="tabpanel" aria-labelledby="row28-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-fever.bge-base-en-v1.5 \
  --topics beir-v1.0.0-fever-test \
  --output run.beir.bge-base-en-v1.5.fever.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fever-test \
  run.beir.bge-base-en-v1.5.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fever-test \
  run.beir.bge-base-en-v1.5.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fever-test \
  run.beir.bge-base-en-v1.5.fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row28-tab6" role="tabpanel" aria-labelledby="row28-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-fever.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-fever-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-fever-test \
  --output run.beir.cohere-embed-english-v3.0.fever.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-fever-test \
  run.beir.cohere-embed-english-v3.0.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-fever-test \
  run.beir.cohere-embed-english-v3.0.fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-fever-test \
  run.beir.cohere-embed-english-v3.0.fever.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: climate-fever -->
<tr class="accordion-toggle collapsed" id="row29" data-toggle="collapse" data-parent="#row29" href="#collapse29">
<td class="expand-button"></td>
<td>climate-fever</td>
<td>  0.1651</td>
<td>  0.4249</td>
<td></td>
<td>  0.2129</td>
<td>  0.4357</td>
<td></td>
<td>  0.2297</td>
<td>  0.5211</td>
<td></td>
<td>  0.2371</td>
<td>  0.5746</td>
<td></td>
<td>  0.3122</td>
<td>  0.6362</td>
<td></td>
<td>  0.2590</td>
<td>  0.5810</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse29" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row29-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row29-tab1-header" data-mdb-toggle="tab" href="#row29-tab1" role="tab" aria-controls="row29-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row29-tab2-header" data-mdb-toggle="tab" href="#row29-tab2" role="tab" aria-controls="row29-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row29-tab3-header" data-mdb-toggle="tab" href="#row29-tab3" role="tab" aria-controls="row29-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row29-tab4-header" data-mdb-toggle="tab" href="#row29-tab4" role="tab" aria-controls="row29-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row29-tab5-header" data-mdb-toggle="tab" href="#row29-tab5" role="tab" aria-controls="row29-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row29-tab6-header" data-mdb-toggle="tab" href="#row29-tab6" role="tab" aria-controls="row29-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row29-content">
  <div class="tab-pane fade show active" id="row29-tab1" role="tabpanel" aria-labelledby="row29-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-climate-fever.flat \
  --topics beir-v1.0.0-climate-fever-test \
  --output run.beir.bm25-flat.climate-fever.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-climate-fever-test \
  run.beir.bm25-flat.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-climate-fever-test \
  run.beir.bm25-flat.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-climate-fever-test \
  run.beir.bm25-flat.climate-fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row29-tab2" role="tabpanel" aria-labelledby="row29-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-climate-fever.multifield \
  --topics beir-v1.0.0-climate-fever-test \
  --output run.beir.bm25-multifield.climate-fever.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-climate-fever-test \
  run.beir.bm25-multifield.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-climate-fever-test \
  run.beir.bm25-multifield.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-climate-fever-test \
  run.beir.bm25-multifield.climate-fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row29-tab3" role="tabpanel" aria-labelledby="row29-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-climate-fever.splade-pp-ed \
  --topics beir-v1.0.0-climate-fever.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.climate-fever.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-climate-fever-test \
  run.beir.splade-pp-ed.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-climate-fever-test \
  run.beir.splade-pp-ed.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-climate-fever-test \
  run.beir.splade-pp-ed.climate-fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row29-tab4" role="tabpanel" aria-labelledby="row29-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-climate-fever.contriever-msmarco \
  --topics beir-v1.0.0-climate-fever-test \
  --output run.beir.contriever-msmarco.climate-fever.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-climate-fever-test \
  run.beir.contriever-msmarco.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-climate-fever-test \
  run.beir.contriever-msmarco.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-climate-fever-test \
  run.beir.contriever-msmarco.climate-fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row29-tab5" role="tabpanel" aria-labelledby="row29-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-climate-fever.bge-base-en-v1.5 \
  --topics beir-v1.0.0-climate-fever-test \
  --output run.beir.bge-base-en-v1.5.climate-fever.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-climate-fever-test \
  run.beir.bge-base-en-v1.5.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-climate-fever-test \
  run.beir.bge-base-en-v1.5.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-climate-fever-test \
  run.beir.bge-base-en-v1.5.climate-fever.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row29-tab6" role="tabpanel" aria-labelledby="row29-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-climate-fever.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-climate-fever-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-climate-fever-test \
  --output run.beir.cohere-embed-english-v3.0.climate-fever.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-climate-fever-test \
  run.beir.cohere-embed-english-v3.0.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-climate-fever-test \
  run.beir.cohere-embed-english-v3.0.climate-fever.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-climate-fever-test \
  run.beir.cohere-embed-english-v3.0.climate-fever.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: scifact -->
<tr class="accordion-toggle collapsed" id="row30" data-toggle="collapse" data-parent="#row30" href="#collapse30">
<td class="expand-button"></td>
<td>scifact</td>
<td>  0.6789</td>
<td>  0.9253</td>
<td></td>
<td>  0.6647</td>
<td>  0.9076</td>
<td></td>
<td>  0.7041</td>
<td>  0.9353</td>
<td></td>
<td>  0.6768</td>
<td>  0.9470</td>
<td></td>
<td>  0.7408</td>
<td>  0.9667</td>
<td></td>
<td>  0.7181</td>
<td>  0.9633</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse30" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row30-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row30-tab1-header" data-mdb-toggle="tab" href="#row30-tab1" role="tab" aria-controls="row30-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row30-tab2-header" data-mdb-toggle="tab" href="#row30-tab2" role="tab" aria-controls="row30-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row30-tab3-header" data-mdb-toggle="tab" href="#row30-tab3" role="tab" aria-controls="row30-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row30-tab4-header" data-mdb-toggle="tab" href="#row30-tab4" role="tab" aria-controls="row30-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row30-tab5-header" data-mdb-toggle="tab" href="#row30-tab5" role="tab" aria-controls="row30-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row30-tab6-header" data-mdb-toggle="tab" href="#row30-tab6" role="tab" aria-controls="row30-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row30-content">
  <div class="tab-pane fade show active" id="row30-tab1" role="tabpanel" aria-labelledby="row30-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-scifact.flat \
  --topics beir-v1.0.0-scifact-test \
  --output run.beir.bm25-flat.scifact.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scifact-test \
  run.beir.bm25-flat.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scifact-test \
  run.beir.bm25-flat.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scifact-test \
  run.beir.bm25-flat.scifact.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row30-tab2" role="tabpanel" aria-labelledby="row30-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-scifact.multifield \
  --topics beir-v1.0.0-scifact-test \
  --output run.beir.bm25-multifield.scifact.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scifact-test \
  run.beir.bm25-multifield.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scifact-test \
  run.beir.bm25-multifield.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scifact-test \
  run.beir.bm25-multifield.scifact.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row30-tab3" role="tabpanel" aria-labelledby="row30-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-scifact.splade-pp-ed \
  --topics beir-v1.0.0-scifact.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.scifact.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scifact-test \
  run.beir.splade-pp-ed.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scifact-test \
  run.beir.splade-pp-ed.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scifact-test \
  run.beir.splade-pp-ed.scifact.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row30-tab4" role="tabpanel" aria-labelledby="row30-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-scifact.contriever-msmarco \
  --topics beir-v1.0.0-scifact-test \
  --output run.beir.contriever-msmarco.scifact.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scifact-test \
  run.beir.contriever-msmarco.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scifact-test \
  run.beir.contriever-msmarco.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scifact-test \
  run.beir.contriever-msmarco.scifact.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row30-tab5" role="tabpanel" aria-labelledby="row30-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-scifact.bge-base-en-v1.5 \
  --topics beir-v1.0.0-scifact-test \
  --output run.beir.bge-base-en-v1.5.scifact.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scifact-test \
  run.beir.bge-base-en-v1.5.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scifact-test \
  run.beir.bge-base-en-v1.5.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scifact-test \
  run.beir.bge-base-en-v1.5.scifact.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row30-tab6" role="tabpanel" aria-labelledby="row30-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-scifact.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-scifact-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-scifact-test \
  --output run.beir.cohere-embed-english-v3.0.scifact.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-scifact-test \
  run.beir.cohere-embed-english-v3.0.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-scifact-test \
  run.beir.cohere-embed-english-v3.0.scifact.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-scifact-test \
  run.beir.cohere-embed-english-v3.0.scifact.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>

    </tbody>
  </table>
</div>

<div style="padding-top: 20px"/>

For cqadupstack collections:

<div class="table-responsive">
  <table class="table">
    <thead>
      <tr>
        <th class="headertop"></th>
        <th class="headertop"></th>
        <th class="headertop" colspan="3"><b>BM25 Flat</b></th>
        <th class="headertop" colspan="3"><b>BM25 Multifield</b></th>
        <th class="headertop" colspan="3"><b>SPLADE++ ED</b></th>
        <th class="headertop" colspan="3"><b>Contriever MSMARCO</b></th>
        <th class="headertop" colspan="3"><b>BGE-base</b></th>
        <th class="headertop" colspan="3"><b>Cohere embed-english</b></th>
      </tr>
      <tr>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
        <th class="headerbottom" scope="col"></th>
        <th class="headerbottom" scope="col">nDCG@10</th>
        <th class="headerbottom" scope="col">R@100</th>
      </tr>
    </thead>
    <tbody>

<!-- Condition: cqadupstack-android -->
<tr class="accordion-toggle collapsed" id="row12" data-toggle="collapse" data-parent="#row12" href="#collapse12">
<td class="expand-button"></td>
<td>cqadupstack-android</td>
<td>  0.3801</td>
<td>  0.6829</td>
<td></td>
<td>  0.3709</td>
<td>  0.6889</td>
<td></td>
<td>  0.3904</td>
<td>  0.7404</td>
<td></td>
<td>  0.4255</td>
<td>  0.7503</td>
<td></td>
<td>  0.5076</td>
<td>  0.8454</td>
<td></td>
<td>  0.5001</td>
<td>  0.8319</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse12" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row12-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row12-tab1-header" data-mdb-toggle="tab" href="#row12-tab1" role="tab" aria-controls="row12-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row12-tab2-header" data-mdb-toggle="tab" href="#row12-tab2" role="tab" aria-controls="row12-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row12-tab3-header" data-mdb-toggle="tab" href="#row12-tab3" role="tab" aria-controls="row12-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row12-tab4-header" data-mdb-toggle="tab" href="#row12-tab4" role="tab" aria-controls="row12-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row12-tab5-header" data-mdb-toggle="tab" href="#row12-tab5" role="tab" aria-controls="row12-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row12-tab6-header" data-mdb-toggle="tab" href="#row12-tab6" role="tab" aria-controls="row12-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row12-content">
  <div class="tab-pane fade show active" id="row12-tab1" role="tabpanel" aria-labelledby="row12-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-android.flat \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.bm25-flat.cqadupstack-android.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-flat.cqadupstack-android.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row12-tab2" role="tabpanel" aria-labelledby="row12-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-android.multifield \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.bm25-multifield.cqadupstack-android.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bm25-multifield.cqadupstack-android.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row12-tab3" role="tabpanel" aria-labelledby="row12-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-android.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-android.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-android.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.splade-pp-ed.cqadupstack-android.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row12-tab4" role="tabpanel" aria-labelledby="row12-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-android.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.contriever-msmarco.cqadupstack-android.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.contriever-msmarco.cqadupstack-android.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row12-tab5" role="tabpanel" aria-labelledby="row12-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-android.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-android.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.bge-base-en-v1.5.cqadupstack-android.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row12-tab6" role="tabpanel" aria-labelledby="row12-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-android.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-android-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-android-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-android-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-android.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-english -->
<tr class="accordion-toggle collapsed" id="row13" data-toggle="collapse" data-parent="#row13" href="#collapse13">
<td class="expand-button"></td>
<td>cqadupstack-english</td>
<td>  0.3453</td>
<td>  0.5757</td>
<td></td>
<td>  0.3321</td>
<td>  0.5842</td>
<td></td>
<td>  0.4079</td>
<td>  0.6946</td>
<td></td>
<td>  0.4326</td>
<td>  0.6935</td>
<td></td>
<td>  0.4857</td>
<td>  0.7586</td>
<td></td>
<td>  0.4909</td>
<td>  0.7573</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse13" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row13-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row13-tab1-header" data-mdb-toggle="tab" href="#row13-tab1" role="tab" aria-controls="row13-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row13-tab2-header" data-mdb-toggle="tab" href="#row13-tab2" role="tab" aria-controls="row13-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row13-tab3-header" data-mdb-toggle="tab" href="#row13-tab3" role="tab" aria-controls="row13-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row13-tab4-header" data-mdb-toggle="tab" href="#row13-tab4" role="tab" aria-controls="row13-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row13-tab5-header" data-mdb-toggle="tab" href="#row13-tab5" role="tab" aria-controls="row13-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row13-tab6-header" data-mdb-toggle="tab" href="#row13-tab6" role="tab" aria-controls="row13-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row13-content">
  <div class="tab-pane fade show active" id="row13-tab1" role="tabpanel" aria-labelledby="row13-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-english.flat \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.bm25-flat.cqadupstack-english.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-flat.cqadupstack-english.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row13-tab2" role="tabpanel" aria-labelledby="row13-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-english.multifield \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.bm25-multifield.cqadupstack-english.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bm25-multifield.cqadupstack-english.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row13-tab3" role="tabpanel" aria-labelledby="row13-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-english.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-english.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-english.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.splade-pp-ed.cqadupstack-english.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row13-tab4" role="tabpanel" aria-labelledby="row13-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-english.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.contriever-msmarco.cqadupstack-english.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.contriever-msmarco.cqadupstack-english.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row13-tab5" role="tabpanel" aria-labelledby="row13-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-english.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-english.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.bge-base-en-v1.5.cqadupstack-english.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row13-tab6" role="tabpanel" aria-labelledby="row13-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-english.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-english-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-english-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-english-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-english.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-gaming -->
<tr class="accordion-toggle collapsed" id="row14" data-toggle="collapse" data-parent="#row14" href="#collapse14">
<td class="expand-button"></td>
<td>cqadupstack-gaming</td>
<td>  0.4822</td>
<td>  0.7651</td>
<td></td>
<td>  0.4418</td>
<td>  0.7571</td>
<td></td>
<td>  0.4957</td>
<td>  0.8131</td>
<td></td>
<td>  0.5276</td>
<td>  0.8481</td>
<td></td>
<td>  0.5967</td>
<td>  0.9036</td>
<td></td>
<td>  0.6050</td>
<td>  0.9003</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse14" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row14-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row14-tab1-header" data-mdb-toggle="tab" href="#row14-tab1" role="tab" aria-controls="row14-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row14-tab2-header" data-mdb-toggle="tab" href="#row14-tab2" role="tab" aria-controls="row14-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row14-tab3-header" data-mdb-toggle="tab" href="#row14-tab3" role="tab" aria-controls="row14-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row14-tab4-header" data-mdb-toggle="tab" href="#row14-tab4" role="tab" aria-controls="row14-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row14-tab5-header" data-mdb-toggle="tab" href="#row14-tab5" role="tab" aria-controls="row14-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row14-tab6-header" data-mdb-toggle="tab" href="#row14-tab6" role="tab" aria-controls="row14-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row14-content">
  <div class="tab-pane fade show active" id="row14-tab1" role="tabpanel" aria-labelledby="row14-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gaming.flat \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.bm25-flat.cqadupstack-gaming.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-flat.cqadupstack-gaming.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row14-tab2" role="tabpanel" aria-labelledby="row14-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gaming.multifield \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.bm25-multifield.cqadupstack-gaming.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bm25-multifield.cqadupstack-gaming.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row14-tab3" role="tabpanel" aria-labelledby="row14-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gaming.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-gaming.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-gaming.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.splade-pp-ed.cqadupstack-gaming.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row14-tab4" role="tabpanel" aria-labelledby="row14-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-gaming.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.contriever-msmarco.cqadupstack-gaming.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.contriever-msmarco.cqadupstack-gaming.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row14-tab5" role="tabpanel" aria-labelledby="row14-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-gaming.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gaming.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row14-tab6" role="tabpanel" aria-labelledby="row14-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-gaming.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-gaming-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-gaming-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gaming-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gaming.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-gis -->
<tr class="accordion-toggle collapsed" id="row15" data-toggle="collapse" data-parent="#row15" href="#collapse15">
<td class="expand-button"></td>
<td>cqadupstack-gis</td>
<td>  0.2901</td>
<td>  0.6119</td>
<td></td>
<td>  0.2904</td>
<td>  0.6458</td>
<td></td>
<td>  0.3150</td>
<td>  0.6320</td>
<td></td>
<td>  0.3022</td>
<td>  0.6272</td>
<td></td>
<td>  0.4127</td>
<td>  0.7682</td>
<td></td>
<td>  0.3917</td>
<td>  0.7439</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse15" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row15-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row15-tab1-header" data-mdb-toggle="tab" href="#row15-tab1" role="tab" aria-controls="row15-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row15-tab2-header" data-mdb-toggle="tab" href="#row15-tab2" role="tab" aria-controls="row15-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row15-tab3-header" data-mdb-toggle="tab" href="#row15-tab3" role="tab" aria-controls="row15-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row15-tab4-header" data-mdb-toggle="tab" href="#row15-tab4" role="tab" aria-controls="row15-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row15-tab5-header" data-mdb-toggle="tab" href="#row15-tab5" role="tab" aria-controls="row15-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row15-tab6-header" data-mdb-toggle="tab" href="#row15-tab6" role="tab" aria-controls="row15-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row15-content">
  <div class="tab-pane fade show active" id="row15-tab1" role="tabpanel" aria-labelledby="row15-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gis.flat \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.bm25-flat.cqadupstack-gis.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-flat.cqadupstack-gis.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row15-tab2" role="tabpanel" aria-labelledby="row15-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gis.multifield \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.bm25-multifield.cqadupstack-gis.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bm25-multifield.cqadupstack-gis.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row15-tab3" role="tabpanel" aria-labelledby="row15-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-gis.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-gis.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-gis.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.splade-pp-ed.cqadupstack-gis.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row15-tab4" role="tabpanel" aria-labelledby="row15-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-gis.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.contriever-msmarco.cqadupstack-gis.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.contriever-msmarco.cqadupstack-gis.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row15-tab5" role="tabpanel" aria-labelledby="row15-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-gis.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-gis.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.bge-base-en-v1.5.cqadupstack-gis.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row15-tab6" role="tabpanel" aria-labelledby="row15-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-gis.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-gis-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-gis-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt

python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-gis-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-gis.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-mathematica -->
<tr class="accordion-toggle collapsed" id="row16" data-toggle="collapse" data-parent="#row16" href="#collapse16">
<td class="expand-button"></td>
<td>cqadupstack-mathematica</td>
<td>  0.2015</td>
<td>  0.4877</td>
<td></td>
<td>  0.2046</td>
<td>  0.5215</td>
<td></td>
<td>  0.2377</td>
<td>  0.5797</td>
<td></td>
<td>  0.2355</td>
<td>  0.5726</td>
<td></td>
<td>  0.3163</td>
<td>  0.6922</td>
<td></td>
<td>  0.3038</td>
<td>  0.6671</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse16" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row16-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row16-tab1-header" data-mdb-toggle="tab" href="#row16-tab1" role="tab" aria-controls="row16-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row16-tab2-header" data-mdb-toggle="tab" href="#row16-tab2" role="tab" aria-controls="row16-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row16-tab3-header" data-mdb-toggle="tab" href="#row16-tab3" role="tab" aria-controls="row16-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row16-tab4-header" data-mdb-toggle="tab" href="#row16-tab4" role="tab" aria-controls="row16-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row16-tab5-header" data-mdb-toggle="tab" href="#row16-tab5" role="tab" aria-controls="row16-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row16-tab6-header" data-mdb-toggle="tab" href="#row16-tab6" role="tab" aria-controls="row16-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row16-content">
  <div class="tab-pane fade show active" id="row16-tab1" role="tabpanel" aria-labelledby="row16-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-mathematica.flat \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.bm25-flat.cqadupstack-mathematica.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-flat.cqadupstack-mathematica.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row16-tab2" role="tabpanel" aria-labelledby="row16-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-mathematica.multifield \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.bm25-multifield.cqadupstack-mathematica.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bm25-multifield.cqadupstack-mathematica.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row16-tab3" role="tabpanel" aria-labelledby="row16-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-mathematica.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-mathematica.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-mathematica.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.splade-pp-ed.cqadupstack-mathematica.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row16-tab4" role="tabpanel" aria-labelledby="row16-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-mathematica.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.contriever-msmarco.cqadupstack-mathematica.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.contriever-msmarco.cqadupstack-mathematica.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row16-tab5" role="tabpanel" aria-labelledby="row16-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-mathematica.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.bge-base-en-v1.5.cqadupstack-mathematica.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row16-tab6" role="tabpanel" aria-labelledby="row16-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-mathematica.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-mathematica-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-mathematica-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-mathematica-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-mathematica.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-physics -->
<tr class="accordion-toggle collapsed" id="row17" data-toggle="collapse" data-parent="#row17" href="#collapse17">
<td class="expand-button"></td>
<td>cqadupstack-physics</td>
<td>  0.3214</td>
<td>  0.6326</td>
<td></td>
<td>  0.3248</td>
<td>  0.6486</td>
<td></td>
<td>  0.3599</td>
<td>  0.7196</td>
<td></td>
<td>  0.4159</td>
<td>  0.7619</td>
<td></td>
<td>  0.4724</td>
<td>  0.8078</td>
<td></td>
<td>  0.4382</td>
<td>  0.7843</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse17" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row17-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row17-tab1-header" data-mdb-toggle="tab" href="#row17-tab1" role="tab" aria-controls="row17-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row17-tab2-header" data-mdb-toggle="tab" href="#row17-tab2" role="tab" aria-controls="row17-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row17-tab3-header" data-mdb-toggle="tab" href="#row17-tab3" role="tab" aria-controls="row17-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row17-tab4-header" data-mdb-toggle="tab" href="#row17-tab4" role="tab" aria-controls="row17-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row17-tab5-header" data-mdb-toggle="tab" href="#row17-tab5" role="tab" aria-controls="row17-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row17-tab6-header" data-mdb-toggle="tab" href="#row17-tab6" role="tab" aria-controls="row17-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row17-content">
  <div class="tab-pane fade show active" id="row17-tab1" role="tabpanel" aria-labelledby="row17-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-physics.flat \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.bm25-flat.cqadupstack-physics.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-flat.cqadupstack-physics.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row17-tab2" role="tabpanel" aria-labelledby="row17-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-physics.multifield \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.bm25-multifield.cqadupstack-physics.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bm25-multifield.cqadupstack-physics.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row17-tab3" role="tabpanel" aria-labelledby="row17-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-physics.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-physics.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-physics.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.splade-pp-ed.cqadupstack-physics.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row17-tab4" role="tabpanel" aria-labelledby="row17-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-physics.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.contriever-msmarco.cqadupstack-physics.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.contriever-msmarco.cqadupstack-physics.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row17-tab5" role="tabpanel" aria-labelledby="row17-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-physics.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-physics.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.bge-base-en-v1.5.cqadupstack-physics.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row17-tab6" role="tabpanel" aria-labelledby="row17-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-physics.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-physics-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-physics-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-physics-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-physics.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-programmers -->
<tr class="accordion-toggle collapsed" id="row18" data-toggle="collapse" data-parent="#row18" href="#collapse18">
<td class="expand-button"></td>
<td>cqadupstack-programmers</td>
<td>  0.2802</td>
<td>  0.5588</td>
<td></td>
<td>  0.2963</td>
<td>  0.6194</td>
<td></td>
<td>  0.3401</td>
<td>  0.6585</td>
<td></td>
<td>  0.3574</td>
<td>  0.7191</td>
<td></td>
<td>  0.4238</td>
<td>  0.7856</td>
<td></td>
<td>  0.4367</td>
<td>  0.7889</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse18" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row18-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row18-tab1-header" data-mdb-toggle="tab" href="#row18-tab1" role="tab" aria-controls="row18-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row18-tab2-header" data-mdb-toggle="tab" href="#row18-tab2" role="tab" aria-controls="row18-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row18-tab3-header" data-mdb-toggle="tab" href="#row18-tab3" role="tab" aria-controls="row18-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row18-tab4-header" data-mdb-toggle="tab" href="#row18-tab4" role="tab" aria-controls="row18-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row18-tab5-header" data-mdb-toggle="tab" href="#row18-tab5" role="tab" aria-controls="row18-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row18-tab6-header" data-mdb-toggle="tab" href="#row18-tab6" role="tab" aria-controls="row18-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row18-content">
  <div class="tab-pane fade show active" id="row18-tab1" role="tabpanel" aria-labelledby="row18-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-programmers.flat \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.bm25-flat.cqadupstack-programmers.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-flat.cqadupstack-programmers.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row18-tab2" role="tabpanel" aria-labelledby="row18-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-programmers.multifield \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.bm25-multifield.cqadupstack-programmers.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bm25-multifield.cqadupstack-programmers.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row18-tab3" role="tabpanel" aria-labelledby="row18-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-programmers.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-programmers.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-programmers.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.splade-pp-ed.cqadupstack-programmers.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row18-tab4" role="tabpanel" aria-labelledby="row18-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-programmers.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.contriever-msmarco.cqadupstack-programmers.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.contriever-msmarco.cqadupstack-programmers.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row18-tab5" role="tabpanel" aria-labelledby="row18-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-programmers.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.bge-base-en-v1.5.cqadupstack-programmers.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row18-tab6" role="tabpanel" aria-labelledby="row18-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-programmers.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-programmers-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-programmers-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-programmers-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-programmers.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-stats -->
<tr class="accordion-toggle collapsed" id="row19" data-toggle="collapse" data-parent="#row19" href="#collapse19">
<td class="expand-button"></td>
<td>cqadupstack-stats</td>
<td>  0.2711</td>
<td>  0.5338</td>
<td></td>
<td>  0.2790</td>
<td>  0.5719</td>
<td></td>
<td>  0.2990</td>
<td>  0.5894</td>
<td></td>
<td>  0.3095</td>
<td>  0.5860</td>
<td></td>
<td>  0.3732</td>
<td>  0.6727</td>
<td></td>
<td>  0.3524</td>
<td>  0.6431</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse19" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row19-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row19-tab1-header" data-mdb-toggle="tab" href="#row19-tab1" role="tab" aria-controls="row19-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row19-tab2-header" data-mdb-toggle="tab" href="#row19-tab2" role="tab" aria-controls="row19-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row19-tab3-header" data-mdb-toggle="tab" href="#row19-tab3" role="tab" aria-controls="row19-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row19-tab4-header" data-mdb-toggle="tab" href="#row19-tab4" role="tab" aria-controls="row19-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row19-tab5-header" data-mdb-toggle="tab" href="#row19-tab5" role="tab" aria-controls="row19-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row19-tab6-header" data-mdb-toggle="tab" href="#row19-tab6" role="tab" aria-controls="row19-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row19-content">
  <div class="tab-pane fade show active" id="row19-tab1" role="tabpanel" aria-labelledby="row19-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-stats.flat \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.bm25-flat.cqadupstack-stats.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-flat.cqadupstack-stats.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row19-tab2" role="tabpanel" aria-labelledby="row19-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-stats.multifield \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.bm25-multifield.cqadupstack-stats.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bm25-multifield.cqadupstack-stats.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row19-tab3" role="tabpanel" aria-labelledby="row19-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-stats.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-stats.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-stats.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.splade-pp-ed.cqadupstack-stats.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row19-tab4" role="tabpanel" aria-labelledby="row19-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-stats.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.contriever-msmarco.cqadupstack-stats.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.contriever-msmarco.cqadupstack-stats.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row19-tab5" role="tabpanel" aria-labelledby="row19-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-stats.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-stats.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.bge-base-en-v1.5.cqadupstack-stats.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row19-tab6" role="tabpanel" aria-labelledby="row19-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-stats.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-stats-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-stats-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-stats-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-stats.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-tex -->
<tr class="accordion-toggle collapsed" id="row20" data-toggle="collapse" data-parent="#row20" href="#collapse20">
<td class="expand-button"></td>
<td>cqadupstack-tex</td>
<td>  0.2244</td>
<td>  0.4686</td>
<td></td>
<td>  0.2086</td>
<td>  0.4954</td>
<td></td>
<td>  0.2530</td>
<td>  0.5161</td>
<td></td>
<td>  0.2209</td>
<td>  0.4985</td>
<td></td>
<td>  0.3115</td>
<td>  0.6489</td>
<td></td>
<td>  0.3083</td>
<td>  0.6235</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse20" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row20-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row20-tab1-header" data-mdb-toggle="tab" href="#row20-tab1" role="tab" aria-controls="row20-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row20-tab2-header" data-mdb-toggle="tab" href="#row20-tab2" role="tab" aria-controls="row20-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row20-tab3-header" data-mdb-toggle="tab" href="#row20-tab3" role="tab" aria-controls="row20-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row20-tab4-header" data-mdb-toggle="tab" href="#row20-tab4" role="tab" aria-controls="row20-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row20-tab5-header" data-mdb-toggle="tab" href="#row20-tab5" role="tab" aria-controls="row20-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row20-tab6-header" data-mdb-toggle="tab" href="#row20-tab6" role="tab" aria-controls="row20-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row20-content">
  <div class="tab-pane fade show active" id="row20-tab1" role="tabpanel" aria-labelledby="row20-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-tex.flat \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.bm25-flat.cqadupstack-tex.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-flat.cqadupstack-tex.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row20-tab2" role="tabpanel" aria-labelledby="row20-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-tex.multifield \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.bm25-multifield.cqadupstack-tex.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bm25-multifield.cqadupstack-tex.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row20-tab3" role="tabpanel" aria-labelledby="row20-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-tex.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-tex.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-tex.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.splade-pp-ed.cqadupstack-tex.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row20-tab4" role="tabpanel" aria-labelledby="row20-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-tex.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.contriever-msmarco.cqadupstack-tex.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.contriever-msmarco.cqadupstack-tex.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row20-tab5" role="tabpanel" aria-labelledby="row20-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-tex.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-tex.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.bge-base-en-v1.5.cqadupstack-tex.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row20-tab6" role="tabpanel" aria-labelledby="row20-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-tex.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-tex-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-tex-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-tex-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-tex.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-unix -->
<tr class="accordion-toggle collapsed" id="row21" data-toggle="collapse" data-parent="#row21" href="#collapse21">
<td class="expand-button"></td>
<td>cqadupstack-unix</td>
<td>  0.2749</td>
<td>  0.5417</td>
<td></td>
<td>  0.2788</td>
<td>  0.5721</td>
<td></td>
<td>  0.3167</td>
<td>  0.6214</td>
<td></td>
<td>  0.3257</td>
<td>  0.6161</td>
<td></td>
<td>  0.4220</td>
<td>  0.7797</td>
<td></td>
<td>  0.4059</td>
<td>  0.7543</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse21" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row21-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row21-tab1-header" data-mdb-toggle="tab" href="#row21-tab1" role="tab" aria-controls="row21-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row21-tab2-header" data-mdb-toggle="tab" href="#row21-tab2" role="tab" aria-controls="row21-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row21-tab3-header" data-mdb-toggle="tab" href="#row21-tab3" role="tab" aria-controls="row21-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row21-tab4-header" data-mdb-toggle="tab" href="#row21-tab4" role="tab" aria-controls="row21-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row21-tab5-header" data-mdb-toggle="tab" href="#row21-tab5" role="tab" aria-controls="row21-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row21-tab6-header" data-mdb-toggle="tab" href="#row21-tab6" role="tab" aria-controls="row21-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row21-content">
  <div class="tab-pane fade show active" id="row21-tab1" role="tabpanel" aria-labelledby="row21-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-unix.flat \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.bm25-flat.cqadupstack-unix.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-flat.cqadupstack-unix.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row21-tab2" role="tabpanel" aria-labelledby="row21-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-unix.multifield \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.bm25-multifield.cqadupstack-unix.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bm25-multifield.cqadupstack-unix.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row21-tab3" role="tabpanel" aria-labelledby="row21-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-unix.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-unix.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-unix.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.splade-pp-ed.cqadupstack-unix.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row21-tab4" role="tabpanel" aria-labelledby="row21-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-unix.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.contriever-msmarco.cqadupstack-unix.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.contriever-msmarco.cqadupstack-unix.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row21-tab5" role="tabpanel" aria-labelledby="row21-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-unix.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-unix.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.bge-base-en-v1.5.cqadupstack-unix.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row21-tab6" role="tabpanel" aria-labelledby="row21-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-unix.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-unix-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-unix-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-unix-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-unix.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-webmasters -->
<tr class="accordion-toggle collapsed" id="row22" data-toggle="collapse" data-parent="#row22" href="#collapse22">
<td class="expand-button"></td>
<td>cqadupstack-webmasters</td>
<td>  0.3059</td>
<td>  0.5820</td>
<td></td>
<td>  0.3008</td>
<td>  0.6100</td>
<td></td>
<td>  0.3167</td>
<td>  0.6360</td>
<td></td>
<td>  0.3392</td>
<td>  0.7032</td>
<td></td>
<td>  0.4072</td>
<td>  0.7774</td>
<td></td>
<td>  0.4068</td>
<td>  0.7485</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse22" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row22-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row22-tab1-header" data-mdb-toggle="tab" href="#row22-tab1" role="tab" aria-controls="row22-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row22-tab2-header" data-mdb-toggle="tab" href="#row22-tab2" role="tab" aria-controls="row22-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row22-tab3-header" data-mdb-toggle="tab" href="#row22-tab3" role="tab" aria-controls="row22-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row22-tab4-header" data-mdb-toggle="tab" href="#row22-tab4" role="tab" aria-controls="row22-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row22-tab5-header" data-mdb-toggle="tab" href="#row22-tab5" role="tab" aria-controls="row22-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row22-tab6-header" data-mdb-toggle="tab" href="#row22-tab6" role="tab" aria-controls="row22-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row22-content">
  <div class="tab-pane fade show active" id="row22-tab1" role="tabpanel" aria-labelledby="row22-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-webmasters.flat \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.bm25-flat.cqadupstack-webmasters.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-flat.cqadupstack-webmasters.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row22-tab2" role="tabpanel" aria-labelledby="row22-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-webmasters.multifield \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.bm25-multifield.cqadupstack-webmasters.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bm25-multifield.cqadupstack-webmasters.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row22-tab3" role="tabpanel" aria-labelledby="row22-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-webmasters.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-webmasters.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-webmasters.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.splade-pp-ed.cqadupstack-webmasters.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row22-tab4" role="tabpanel" aria-labelledby="row22-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-webmasters.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.contriever-msmarco.cqadupstack-webmasters.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.contriever-msmarco.cqadupstack-webmasters.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row22-tab5" role="tabpanel" aria-labelledby="row22-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-webmasters.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.bge-base-en-v1.5.cqadupstack-webmasters.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row22-tab6" role="tabpanel" aria-labelledby="row22-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-webmasters.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-webmasters-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-webmasters-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-webmasters-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-webmasters.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>
<!-- Condition: cqadupstack-wordpress -->
<tr class="accordion-toggle collapsed" id="row23" data-toggle="collapse" data-parent="#row23" href="#collapse23">
<td class="expand-button"></td>
<td>cqadupstack-wordpress</td>
<td>  0.2483</td>
<td>  0.5152</td>
<td></td>
<td>  0.2562</td>
<td>  0.5526</td>
<td></td>
<td>  0.2733</td>
<td>  0.5945</td>
<td></td>
<td>  0.2532</td>
<td>  0.5769</td>
<td></td>
<td>  0.3547</td>
<td>  0.7047</td>
<td></td>
<td>  0.3426</td>
<td>  0.6937</td>
</tr>
<tr class="hide-table-padding">
<td></td>
<td colspan="15">
<div id="collapse23" class="collapse in p-3">

<!-- Tabs navs -->
<ul class="nav nav-tabs mb-3" id="row23-tabs" role="tablist">
  <li class="nav-item" role="presentation">
    <a class="nav-link active" id="row23-tab1-header" data-mdb-toggle="tab" href="#row23-tab1" role="tab" aria-controls="row23-tab1" aria-selected="true" style="text-transform:none">BM25 Flat</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row23-tab2-header" data-mdb-toggle="tab" href="#row23-tab2" role="tab" aria-controls="row23-tab2" aria-selected="false" style="text-transform:none">BM25 Multifield</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row23-tab3-header" data-mdb-toggle="tab" href="#row23-tab3" role="tab" aria-controls="row23-tab3" aria-selected="false" style="text-transform:none">SPLADE</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row23-tab4-header" data-mdb-toggle="tab" href="#row23-tab4" role="tab" aria-controls="row23-tab4" aria-selected="false" style="text-transform:none">Contriever MSMARCO</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row23-tab5-header" data-mdb-toggle="tab" href="#row23-tab5" role="tab" aria-controls="row23-tab5" aria-selected="false" style="text-transform:none">BGE-base</a>
  </li>
  <li class="nav-item" role="presentation">
    <a class="nav-link" id="row23-tab6-header" data-mdb-toggle="tab" href="#row23-tab6" role="tab" aria-controls="row23-tab6" aria-selected="false" style="text-transform:none">Cohere embed-english</a>
  </li>
</ul>
<!-- Tabs navs -->

<!-- Tabs content -->
<div class="tab-content" id="row23-content">
  <div class="tab-pane fade show active" id="row23-tab1" role="tabpanel" aria-labelledby="row23-tab1">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-wordpress.flat \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.bm25-flat.cqadupstack-wordpress.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-flat.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row23-tab2" role="tabpanel" aria-labelledby="row23-tab2">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-wordpress.multifield \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.bm25-multifield.cqadupstack-wordpress.txt \
  --output-format trec \
  --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bm25-multifield.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row23-tab3" role="tabpanel" aria-labelledby="row23-tab3">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.lucene \
  --threads 16 --batch-size 128 \
  --index beir-v1.0.0-cqadupstack-wordpress.splade-pp-ed \
  --topics beir-v1.0.0-cqadupstack-wordpress.test.splade-pp-ed \
  --output run.beir.splade-pp-ed.cqadupstack-wordpress.txt \
  --output-format trec \
  --hits 1000 --impact --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.splade-pp-ed.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row23-tab4" role="tabpanel" aria-labelledby="row23-tab4">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class contriever --encoder facebook/contriever-msmarco \
  --index beir-v1.0.0-cqadupstack-wordpress.contriever-msmarco \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.contriever-msmarco.cqadupstack-wordpress.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.contriever-msmarco.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row23-tab5" role="tabpanel" aria-labelledby="row23-tab5">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm \
  --query-prefix "Represent this sentence for searching relevant passages:" \
  --index beir-v1.0.0-cqadupstack-wordpress.bge-base-en-v1.5 \
  --topics beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.bge-base-en-v1.5.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
  <div class="tab-pane fade" id="row23-tab6" role="tabpanel" aria-labelledby="row23-tab6">
Command to generate run:

  <blockquote class="mycode">
<pre><code>python -m pyserini.search.faiss \
  --threads 16 --batch-size 512 \
  --index beir-v1.0.0-cqadupstack-wordpress.cohere-embed-english-v3.0  \
  --topics beir-v1.0.0-cqadupstack-wordpress-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-cqadupstack-wordpress-test \
  --output run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt \
  --hits 1000 --remove-query
</code></pre></blockquote>
Evaluation commands:

  <blockquote class="mycode">
<pre><code>python -m pyserini.eval.trec_eval \
  -c -m ndcg_cut.10 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.100 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt

python -m pyserini.eval.trec_eval \
  -c -m recall.1000 beir-v1.0.0-cqadupstack-wordpress-test \
  run.beir.cohere-embed-english-v3.0.cqadupstack-wordpress.txt</code></pre>
  </blockquote>

  </div>
</div>
<!-- Tabs content -->

</div></td>
</tr>

    </tbody>
  </table>
</div>

<ul style="list-style-type:none; padding-top: 25px">

<li><p>[1] Ehsan Kamalloo, Nandan Thakur, Carlos Lassance, Xueguang Ma, Jheng-Hong Yang, and Jimmy Lin.
<a href="https://arxiv.org/abs/2306.07471">Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard.</a>
<i>arXiv:2306.07471</i>, June 2023.</p></li>

<li><p>[2] Thibault Formal, Carlos Lassance, Benjamin Piwowarski, and Stphane Clinchant.
<a href="https://dl.acm.org/doi/10.1145/3477495.3531857">From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective.</a>
<i>Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</i>, pages 23532359.</p></li>

<li><p>[3] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave.
<a href="https://arxiv.org/abs/2112.09118">Towards Unsupervised Dense Information Retrieval with Contrastive Learning.</a>
<i>arXiv:2112.09118</i>, December 2021.</p></li>

<li><p>[4] Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff.
<a href="https://arxiv.org/abs/2309.07597">C-Pack: Packaged Resources To Advance General Chinese Embedding.</a>
<i>arXiv:2309.07597</i>, December 2023.</p></li>

</ul>

<div style="padding-top: 20px"/>

<h4>Programmatic Execution</h4>

<p>All experimental runs shown in the above table can be programmatically executed based on the instructions below.
To list all the experimental conditions:</p>

<blockquote class="mycode2"><tt>
python -m pyserini.2cr.beir --list-conditions
</tt></blockquote>

<p>These conditions correspond to the table rows above.</p>

<p>For all conditions, just show the commands in a "dry run":</p>

<blockquote class="mycode2"><tt>
python -m pyserini.2cr.beir --all --display-commands --dry-run
</tt></blockquote>

<p>To actually run all the experimental conditions:</p>

<blockquote class="mycode2"><tt>
python -m pyserini.2cr.beir --all --display-commands
</tt></blockquote>

<p>With the above command, run files will be placed in the current directory.
Use the option <tt>--directory runs/</tt> to place the runs in a sub-directory.</p>

<p>To show the commands for a specific condition:</p>

<blockquote class="mycode2"><tt>
python -m pyserini.2cr.beir --condition bm25-flat --display-commands --dry-run
</tt></blockquote>

<p>This will generate exactly the commands for a specific condition above (corresponding to a row in the table).</p>

<p>To actually run a specific condition:</p>

<blockquote class="mycode2"><tt>
python -m pyserini.2cr.beir --condition bm25-flat --display-commands
</tt></blockquote>

<p>Again, with the above command, run files will be placed in the current directory.
Use the option <tt>--directory runs/</tt> to place the runs in a sub-directory.</p>

<p>Finally, to generate this page:</p>

<blockquote class="mycode2"><tt>
python -m pyserini.2cr.beir --generate-report --output beir.html
</tt></blockquote>

<p>The output file <tt>beir.html</tt> should be identical to this page.</p>

<div style="padding-top: 50px"/>

      </div>



    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdb-ui-kit/4.0.0/mdb.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.10/clipboard.min.js"></script>

<script>
document.querySelectorAll('pre').forEach(function (codeBlock) {
    var button = document.createElement('button');
    button.className = 'copy-code-button';
    button.type = 'button';
    var s = codeBlock.innerText;
    button.setAttribute('data-clipboard-text',s);
    button.innerText = 'Copy';

    // var pre = codeBlock.parentNode;
    codeBlock.classList.add('prettyprint');
    // pre.parentNode.insertBefore(button, pre);
    codeBlock.appendChild(button);
});

var clipboard = new ClipboardJS('.copy-code-button');

clipboard.on('success', function(e) {
  console.info('Action:', e.action);
  console.info('Text:', e.text);
  console.info('Trigger:', e.trigger);
  e.trigger.textContent = 'Copied';
  window.setTimeout(function() {
    e.trigger.textContent = 'Copy';
  }, 2000);
  e.clearSelection();
});

clipboard.on('error', function(e) {
  console.error('Action:', e.action);
  console.error('Trigger:', e.trigger);
  e.trigger.textContent = 'Error Copying';
  window.setTimeout(function() {
    e.trigger.textContent = 'Copy';
  }, 2000);
  e.clearSelection();
});

</script>

</body>
</html>
